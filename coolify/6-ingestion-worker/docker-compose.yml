version: '3.8'

services:
  ragfab-ingestion-worker:
    build:
      context: .
      dockerfile: ingestion-worker/Dockerfile
    container_name: ragfab-ingestion-worker
    environment:
      # Database connection
      DATABASE_URL: ${DATABASE_URL:-postgresql://raguser:ragpass@ragfab-postgres.internal:5432/ragdb}

      # Embeddings service
      EMBEDDINGS_API_URL: ${EMBEDDINGS_API_URL:-http://ragfab-embeddings.internal:8001}
      EMBEDDING_DIMENSION: ${EMBEDDING_DIMENSION:-1024}

      # Chunking configuration
      CHUNK_SIZE: ${CHUNK_SIZE:-1500}
      CHUNK_OVERLAP: ${CHUNK_OVERLAP:-200}
      USE_SEMANTIC_CHUNKING: ${USE_SEMANTIC_CHUNKING:-true}

      # Worker configuration
      WORKER_POLL_INTERVAL: ${WORKER_POLL_INTERVAL:-3}
      WORKER_TIMEOUT_MINUTES: ${WORKER_TIMEOUT_MINUTES:-30}
      UPLOADS_DIR: ${UPLOADS_DIR:-/app/uploads}

      # Cache Hugging Face (pour les modèles ML)
      HF_HOME: ${HF_HOME:-/home/worker/.cache/huggingface}

      # Logs
      LOG_LEVEL: ${LOG_LEVEL:-INFO}

    # Volume partagé avec l'API backend pour les fichiers uploadés
    volumes:
      # Uploads (bind mount sur répertoire hôte partagé avec backend)
      - /opt/ragfab/uploads:/app/uploads
      # Cache des modèles ML
      - model_cache:/home/worker/.cache

    restart: unless-stopped

    # Limites de ressources
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 4G
        reservations:
          cpus: '1'
          memory: 2G

    # Healthcheck (vérifie que le worker est actif)
    healthcheck:
      test: ["CMD", "python", "-c", "import sys; sys.exit(0)"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    networks:
      - coolify

volumes:
  # Cache local pour les modèles ML
  model_cache:
    driver: local

networks:
  coolify:
    external: true
    name: coolify
