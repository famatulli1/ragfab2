"""
Service d'analyse IA pour la validation des thumbs down

Ce service analyse automatiquement les thumbs down avec un LLM pour classifier
les probl√®mes et d√©terminer les actions appropri√©es.
"""

import os
import json
import logging
from typing import Dict, Any, Optional
from uuid import UUID
import asyncpg
import httpx

logger = logging.getLogger(__name__)


class ThumbsDownAnalyzer:
    """Analyse IA des thumbs down pour classification et recommandations"""

    def __init__(self, db_pool: asyncpg.Pool):
        self.db = db_pool
        self.confidence_threshold = float(os.getenv("THUMBS_DOWN_CONFIDENCE_THRESHOLD", "0.7"))

        # LLM Configuration
        self.llm_provider = os.getenv("THUMBS_DOWN_LLM_PROVIDER", os.getenv("RAG_PROVIDER", "mistral"))
        self.llm_api_url = os.getenv("LLM_API_URL", "https://api.mistral.ai")
        self.llm_api_key = os.getenv("LLM_API_KEY", "")
        self.llm_model = os.getenv("LLM_MODEL_NAME", "mistral-small-latest")
        self.llm_timeout = float(os.getenv("LLM_TIMEOUT", "60.0"))

        logger.info(f"ThumbsDownAnalyzer initialized with provider={self.llm_provider}, model={self.llm_model}")

    async def analyze_thumbs_down(self, rating_id: UUID) -> Dict[str, Any]:
        """
        Analyse compl√®te d'un thumbs down avec classification IA

        Args:
            rating_id: UUID du rating √† analyser

        Returns:
            Dict avec validation_id, classification, confidence, needs_review
        """
        try:
            # 1. R√©cup√©rer contexte complet du rating
            context = await self._get_rating_context(rating_id)

            if not context:
                logger.error(f"Rating {rating_id} not found or invalid")
                return {"error": "Rating not found"}

            # 2. Construire prompt pour LLM
            prompt = self._build_analysis_prompt(context)

            # 3. Appeler LLM pour classification
            logger.info(f"Analyzing thumbs down {rating_id} with {self.llm_provider}")
            response = await self._call_llm(prompt)

            # 4. Parser r√©ponse JSON du LLM
            classification = response.get('classification', 'unrealistic_expectations')
            confidence = float(response.get('confidence', 0.5))
            reasoning = response.get('reasoning', 'Analyse IA non disponible')
            suggested_reformulation = response.get('suggested_reformulation')
            missing_info_details = response.get('missing_info')

            # 5. D√©terminer si r√©vision admin n√©cessaire
            needs_review = (
                confidence < self.confidence_threshold or
                classification == 'unrealistic_expectations'
            )

            # 6. Enregistrer analyse dans la base
            validation_id = await self._save_validation(
                rating_id=rating_id,
                context=context,
                classification=classification,
                confidence=confidence,
                reasoning=reasoning,
                suggested_reformulation=suggested_reformulation,
                missing_info_details=missing_info_details,
                needs_review=needs_review
            )

            logger.info(f"‚úÖ Analysis completed: validation_id={validation_id}, classification={classification}, confidence={confidence:.2f}, needs_review={needs_review}")

            return {
                'validation_id': str(validation_id),
                'classification': classification,
                'confidence': confidence,
                'needs_review': needs_review,
                'reasoning': reasoning
            }

        except Exception as e:
            logger.error(f"‚ùå Error analyzing thumbs down {rating_id}: {e}", exc_info=True)
            return {"error": str(e)}

    async def _get_rating_context(self, rating_id: UUID) -> Optional[Dict[str, Any]]:
        """R√©cup√®re le contexte complet d'un rating pour l'analyse"""
        async with self.db.acquire() as conn:
            row = await conn.fetchrow("""
                SELECT
                    mr.id as rating_id,
                    mr.message_id,
                    mr.user_id,
                    mr.rating,
                    mr.feedback as user_feedback,
                    u.username,
                    u.email as user_email,
                    u.first_name,
                    u.last_name,
                    m.role as message_role,
                    m.content as message_content,
                    m.sources,
                    c.id as conversation_id,
                    c.title as conversation_title,
                    -- R√©cup√©rer le message user pr√©c√©dent (la question)
                    (
                        SELECT content
                        FROM messages pm
                        WHERE pm.conversation_id = c.id
                          AND pm.role = 'user'
                          AND pm.created_at < m.created_at
                        ORDER BY pm.created_at DESC
                        LIMIT 1
                    ) as user_question
                FROM message_ratings mr
                JOIN messages m ON mr.message_id = m.id
                JOIN conversations c ON m.conversation_id = c.id
                JOIN users u ON mr.user_id = u.id
                WHERE mr.id = $1
            """, rating_id)

            if not row:
                return None

            return dict(row)

    def _build_analysis_prompt(self, context: Dict[str, Any]) -> str:
        """Construit le prompt pour le LLM avec le contexte complet"""

        sources_summary = "Aucune source utilis√©e"
        if context.get('sources'):
            try:
                sources = json.loads(context['sources']) if isinstance(context['sources'], str) else context['sources']
                sources_summary = f"{len(sources)} chunks utilis√©s"
            except:
                sources_summary = "Sources non analysables"

        return f"""Tu es un expert en analyse de qualit√© RAG et accompagnement utilisateur.

Analyse ce thumbs down et classifie-le dans UNE SEULE cat√©gorie parmi les 4 suivantes :

**CONTEXTE** :
- Utilisateur : {context.get('username', 'Unknown')} ({context.get('first_name', '')} {context.get('last_name', '')})
- Email : {context.get('user_email', 'N/A')}
- Question utilisateur : "{context.get('user_question', 'Question non disponible')}"
- R√©ponse syst√®me : "{context.get('message_content', '')[:500]}..." (tronqu√©e)
- Sources utilis√©es : {sources_summary}
- Feedback textuel : "{context.get('user_feedback') or 'Aucun feedback fourni'}"

**CAT√âGORIES DE CLASSIFICATION** :

1. **bad_question** : Question mal formul√©e
   - Crit√®res : Orthographe incorrecte, grammaire incorrecte, question trop vague/ambigu√´, manque de contexte
   - Indicateurs : Fautes d'orthographe, mots manquants, formulation incompr√©hensible
   - Action recommand√©e : Accompagner l'utilisateur pour reformuler
   - Si tu choisis cette cat√©gorie, fournis obligatoirement une suggested_reformulation

2. **bad_answer** : R√©ponse incorrecte/incompl√®te
   - Crit√®res : Le syst√®me a fourni une mauvaise r√©ponse malgr√© des sources correctes
   - Indicateurs : Erreur de synth√®se, hallucination, r√©ponse partielle alors que l'info existe dans les sources
   - Action recommand√©e : Analyse du prompt ou du mod√®le LLM

3. **missing_sources** : Sources pertinentes absentes
   - Crit√®res : L'information demand√©e n'a pas √©t√© trouv√©e car elle n'est pas index√©e
   - Indicateurs : "Je ne trouve pas d'information", sources non pertinentes, aucune source
   - Action recommand√©e : Marquer le document pour r√©ingestion
   - Si tu choisis cette cat√©gorie, fournis obligatoirement missing_info avec pr√©cisions

4. **unrealistic_expectations** : Attentes hors scope
   - Crit√®res : L'utilisateur demande quelque chose qui n'est pas dans la base documentaire
   - Indicateurs : Questions sur des sujets non couverts, demande d'opinions personnelles, cr√©ativit√©
   - Action recommand√©e : Expliquer √† l'utilisateur les limites du syst√®me

**INSTRUCTIONS IMPORTANTES** :
- Analyse principalement la QUESTION et la R√âPONSE, pas uniquement le feedback utilisateur
- Le feedback peut √™tre vide, ne te base pas uniquement dessus
- Si la question contient des fautes d'orthographe √©videntes ‚Üí bad_question
- Si la r√©ponse dit "je ne trouve pas" ou sources vides ‚Üí missing_sources
- Si la r√©ponse est incorrecte malgr√© de bonnes sources ‚Üí bad_answer
- Si la question est hors scope documentaire ‚Üí unrealistic_expectations

**FORMAT DE R√âPONSE ATTENDU (JSON strict)** :
{{
  "classification": "bad_question|bad_answer|missing_sources|unrealistic_expectations",
  "confidence": 0.0-1.0,
  "reasoning": "Explication d√©taill√©e de ta classification (2-3 phrases)",
  "suggested_reformulation": "Reformulation sugg√©r√©e (OBLIGATOIRE si bad_question, sinon null)",
  "missing_info": "D√©tails sur l'info manquante (OBLIGATOIRE si missing_sources, sinon null)"
}}

**EXEMPLES** :

Exemple 1 - bad_question :
{{
  "classification": "bad_question",
  "confidence": 0.95,
  "reasoning": "La question contient des fautes d'orthographe ('proceduree', 'telletravail') et est mal structur√©e, ce qui rend difficile la compr√©hension de l'intention.",
  "suggested_reformulation": "Quelle est la proc√©dure pour demander le t√©l√©travail ?",
  "missing_info": null
}}

Exemple 2 - missing_sources :
{{
  "classification": "missing_sources",
  "confidence": 0.85,
  "reasoning": "La r√©ponse indique 'Je ne trouve pas d'information sur ce sujet' et aucune source n'est fournie. L'utilisateur cherche une info sp√©cifique sur un logiciel interne.",
  "suggested_reformulation": null,
  "missing_info": "Documentation du logiciel PeopleDoc pour gestion des absences"
}}

R√©ponds UNIQUEMENT avec le JSON, sans texte additionnel avant ou apr√®s."""

    async def _call_llm(self, prompt: str) -> Dict[str, Any]:
        """Appelle le LLM pour analyser le thumbs down"""

        try:
            async with httpx.AsyncClient(timeout=self.llm_timeout) as client:
                # Construction de la requ√™te OpenAI-compatible
                headers = {
                    "Content-Type": "application/json",
                }

                if self.llm_api_key:
                    headers["Authorization"] = f"Bearer {self.llm_api_key}"

                payload = {
                    "model": self.llm_model,
                    "messages": [
                        {
                            "role": "system",
                            "content": "Tu es un expert en analyse de qualit√© RAG. R√©ponds toujours en JSON strict."
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.1,  # Temp√©rature basse pour r√©ponses d√©terministes
                    "max_tokens": 500
                }

                response = await client.post(
                    f"{self.llm_api_url}/v1/chat/completions",
                    headers=headers,
                    json=payload
                )

                response.raise_for_status()
                data = response.json()

                # Extraire le contenu de la r√©ponse
                content = data['choices'][0]['message']['content']

                # Parser le JSON (nettoyer markdown si pr√©sent)
                content = content.strip()
                if content.startswith("```json"):
                    content = content[7:]
                if content.endswith("```"):
                    content = content[:-3]
                content = content.strip()

                result = json.loads(content)

                logger.debug(f"LLM response: {result}")

                return result

        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse LLM JSON response: {e}")
            # Fallback avec classification par d√©faut
            return {
                "classification": "unrealistic_expectations",
                "confidence": 0.3,
                "reasoning": f"Erreur de parsing JSON: {str(e)}",
                "suggested_reformulation": null,
                "missing_info": null
            }
        except httpx.HTTPError as e:
            logger.error(f"HTTP error calling LLM: {e}")
            return {
                "classification": "unrealistic_expectations",
                "confidence": 0.3,
                "reasoning": f"Erreur API: {str(e)}",
                "suggested_reformulation": null,
                "missing_info": null
            }
        except Exception as e:
            logger.error(f"Unexpected error calling LLM: {e}", exc_info=True)
            return {
                "classification": "unrealistic_expectations",
                "confidence": 0.3,
                "reasoning": f"Erreur inattendue: {str(e)}",
                "suggested_reformulation": null,
                "missing_info": null
            }

    def _determine_admin_action(self, classification: str, confidence: float) -> str:
        """
        D√©termine automatiquement l'action admin bas√©e sur la classification et la confiance

        Logique :
        - bad_question avec confiance >= seuil ‚Üí contact_user (accompagner l'utilisateur)
        - missing_sources avec confiance >= seuil ‚Üí mark_for_reingestion (r√©ing√©rer document)
        - bad_answer ‚Üí pending (n√©cessite r√©vision manuelle par admin)
        - out_of_scope ‚Üí ignore (thumbs down l√©gitime, aucune action)
        - Toute classification avec confiance < seuil ‚Üí pending (r√©vision manuelle)

        Args:
            classification: Type de probl√®me d√©tect√© (bad_question, missing_sources, etc.)
            confidence: Score de confiance de l'IA (0.0-1.0)

        Returns:
            Action admin recommand√©e ('contact_user', 'mark_for_reingestion', 'ignore', 'pending')
        """
        # Si confiance faible, toujours requiert r√©vision manuelle
        if confidence < self.confidence_threshold:
            return 'pending'

        # Logique bas√©e sur classification avec haute confiance
        if classification == 'bad_question':
            return 'contact_user'  # Utilisateur a mal formul√© sa question
        elif classification == 'missing_sources':
            return 'mark_for_reingestion'  # Document manque d'informations
        elif classification == 'out_of_scope':
            return 'ignore'  # Question hors p√©rim√®tre, thumbs down l√©gitime
        elif classification == 'bad_answer':
            return 'pending'  # R√©ponse incorrecte, n√©cessite investigation humaine
        else:
            # Classification inconnue ou unrealistic_expectations
            return 'pending'

    async def _save_validation(
        self,
        rating_id: UUID,
        context: Dict[str, Any],
        classification: str,
        confidence: float,
        reasoning: str,
        suggested_reformulation: Optional[str],
        missing_info_details: Optional[str],
        needs_review: bool
    ) -> UUID:
        """Enregistre l'analyse dans thumbs_down_validations"""

        # D√©terminer automatiquement l'action admin bas√©e sur classification et confiance
        admin_action = self._determine_admin_action(classification, confidence)

        logger.info(f"üí° Auto-action d√©termin√©e: {admin_action} (classification={classification}, confidence={confidence:.2f})")

        async with self.db.acquire() as conn:
            row = await conn.fetchrow("""
                INSERT INTO thumbs_down_validations (
                    message_id,
                    rating_id,
                    user_id,
                    user_question,
                    assistant_response,
                    sources_used,
                    user_feedback,
                    ai_classification,
                    ai_confidence,
                    ai_reasoning,
                    suggested_reformulation,
                    missing_info_details,
                    needs_admin_review,
                    admin_action
                ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12, $13, $14)
                ON CONFLICT (message_id) DO UPDATE
                SET ai_classification = $8,
                    ai_confidence = $9,
                    ai_reasoning = $10,
                    suggested_reformulation = $11,
                    missing_info_details = $12,
                    needs_admin_review = $13,
                    admin_action = $14,
                    created_at = CURRENT_TIMESTAMP
                RETURNING id
            """,
                context['message_id'],
                rating_id,
                context['user_id'],
                context.get('user_question', ''),
                context.get('message_content', ''),
                json.dumps(context.get('sources')) if context.get('sources') else None,
                context.get('user_feedback'),
                classification,
                confidence,
                reasoning,
                suggested_reformulation,
                missing_info_details,
                needs_review,
                admin_action
            )

            validation_id = row['id']

            # Si action automatique = mark_for_reingestion, synchroniser imm√©diatement
            if admin_action == 'mark_for_reingestion':
                logger.info(f"üîÑ Auto-syncing validation {validation_id} to document_quality_scores")

                try:
                    # Sync vers document_quality_scores
                    result = await conn.execute("""
                        INSERT INTO document_quality_scores (
                            document_id,
                            needs_reingestion,
                            reingestion_reason,
                            updated_at
                        )
                        SELECT DISTINCT
                            c.document_id,
                            true AS needs_reingestion,
                            $2 AS reingestion_reason,
                            NOW() AS updated_at
                        FROM thumbs_down_validations v
                        CROSS JOIN LATERAL jsonb_array_elements(v.sources_used) as source
                        JOIN chunks c ON c.id = (source->>'chunk_id')::UUID
                        WHERE v.id = $1
                            AND v.sources_used IS NOT NULL
                            AND jsonb_typeof(v.sources_used) = 'array'

                        ON CONFLICT (document_id) DO UPDATE
                        SET
                            needs_reingestion = true,
                            updated_at = NOW(),
                            reingestion_reason = COALESCE(
                                document_quality_scores.reingestion_reason || ' | ',
                                ''
                            ) || EXCLUDED.reingestion_reason
                    """, validation_id, f"AI auto-classification: {classification} (confidence={confidence:.2f})")

                    # Extraire nombre de documents synchronis√©s
                    status = result.split()
                    count = int(status[-1]) if status else 0

                    if count > 0:
                        logger.info(f"‚úÖ Auto-synced {count} document(s) from validation {validation_id}")
                    else:
                        logger.warning(f"‚ö†Ô∏è No documents found to sync from validation {validation_id}")

                except Exception as sync_error:
                    # Ne pas bloquer si sync √©choue (graceful degradation)
                    logger.error(f"‚ùå Error auto-syncing validation {validation_id}: {sync_error}")

            return validation_id
