# Guide Administrateur Technique - RAGFab

**Version**: 2.0
**Date**: Janvier 2025
**Public**: Administrateurs systÃ¨me avec connaissances techniques limitÃ©es

---

## ğŸ“‹ Table des matiÃ¨res

1. [Vue d'ensemble de l'architecture](#1-vue-densemble-de-larchitecture)
2. [Interface utilisateur (Frontend)](#2-interface-utilisateur-frontend)
3. [Interface administrateur](#3-interface-administrateur)
4. [Pipeline d'ingestion des documents](#4-pipeline-dingestion-des-documents)
5. [StratÃ©gies de dÃ©coupage (Chunking)](#5-stratÃ©gies-de-dÃ©coupage-chunking)
6. [SystÃ¨me de recherche](#6-systÃ¨me-de-recherche)
7. [Recherche hybride en dÃ©tail](#7-recherche-hybride-en-dÃ©tail)
8. [Reranking (reclassement)](#8-reranking-reclassement)
9. [SystÃ¨me de notation et amÃ©lioration](#9-systÃ¨me-de-notation-et-amÃ©lioration)
10. [RÃ©ingestion des documents](#10-rÃ©ingestion-des-documents)
11. [Glossaire des termes techniques](#11-glossaire-des-termes-techniques)

---

## 1. Vue d'ensemble de l'architecture

### 1.1 SchÃ©ma gÃ©nÃ©ral du systÃ¨me

RAGFab est composÃ© de **7 composants principaux** qui travaillent ensemble :

```mermaid
graph TB
    subgraph "ğŸŒ Frontend (Interface Web)"
        UI[Interface Utilisateur<br/>Port 5173]
        Admin[Interface Admin<br/>Gestion documents]
    end

    subgraph "ğŸ”§ Backend (Serveur)"
        API[Web API FastAPI<br/>Port 8000]
        Worker[Ingestion Worker<br/>Traitement documents]
    end

    subgraph "ğŸ§  Services IA"
        Embed[Service Embeddings<br/>E5-Large<br/>Port 8001]
        Rerank[Service Reranker<br/>BGE-M3<br/>Port 8002]
    end

    subgraph "ğŸ’¾ Stockage"
        DB[(PostgreSQL + PGVector<br/>Port 5432)]
        Files[/app/uploads<br/>Fichiers]
    end

    UI --> API
    Admin --> API
    API --> Embed
    API --> Rerank
    API --> DB
    Worker --> Embed
    Worker --> DB
    Worker --> Files
    API --> Files

    style UI fill:#e3f2fd
    style Admin fill:#e3f2fd
    style API fill:#fff3e0
    style Worker fill:#fff3e0
    style Embed fill:#f3e5f5
    style Rerank fill:#f3e5f5
    style DB fill:#e8f5e9
    style Files fill:#e8f5e9
```

### 1.2 RÃ´le de chaque composant

| Composant | RÃ´le | Analogie |
|-----------|------|----------|
| **Frontend** | Interface web oÃ¹ les utilisateurs posent des questions | Le guichet d'accueil d'une bibliothÃ¨que |
| **Web API** | Coordonne toutes les opÃ©rations, gÃ¨re les requÃªtes | Le bibliothÃ©caire qui organise tout |
| **Ingestion Worker** | Traite les documents uploadÃ©s en arriÃ¨re-plan | Le catalogueur qui range les nouveaux livres |
| **Service Embeddings** | Transforme le texte en vecteurs mathÃ©matiques | Le systÃ¨me de classification Dewey qui attribue des codes aux livres |
| **Service Reranker** | Affine les rÃ©sultats de recherche | L'expert qui trie les livres trouvÃ©s par pertinence |
| **PostgreSQL** | Stocke documents, chunks et vecteurs | Les rayonnages de la bibliothÃ¨que |
| **Fichiers (/app/uploads)** | Stocke les fichiers PDF originaux et images | Les archives avec documents originaux |

---

## 2. Interface utilisateur (Frontend)

### 2.1 Espace de conversation

L'interface principale permet aux utilisateurs de :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAGFab - Interface de Chat                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  ğŸ‘¤ Utilisateur: "Quelle est la procÃ©dure RTT ?"       â”‚
â”‚                                                         â”‚
â”‚  ğŸ¤– Assistant: "La procÃ©dure RTT consiste Ã ..."        â”‚
â”‚     ğŸ“„ Sources:                                         â”‚
â”‚     â€¢ Document_RH.pdf (page 12) - Score: 0.89         â”‚
â”‚     â€¢ Reglement_interieur.pdf (page 5) - Score: 0.82  â”‚
â”‚                                                         â”‚
â”‚     ğŸ‘ ğŸ‘  [Boutons de notation]                       â”‚
â”‚                                                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ’¬ Votre question...                    [Envoyer] ğŸ”  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**FonctionnalitÃ©s clÃ©s** :
- ğŸ’¬ **Conversation continue** : Le systÃ¨me se souvient du contexte
- ğŸ“š **Affichage des sources** : Chaque rÃ©ponse cite ses documents sources
- ğŸ¯ **Score de pertinence** : Indique la confiance (0.0 Ã  1.0)
- ğŸ‘ğŸ‘ **Notation** : Les utilisateurs Ã©valuent la qualitÃ© des rÃ©ponses
- ğŸ–¼ï¸ **Images intÃ©grÃ©es** : Les diagrammes et tableaux sont affichÃ©s

### 2.2 Recherche hybride (toggle + curseur)

L'utilisateur peut activer la recherche hybride pour amÃ©liorer les rÃ©sultats :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”€ Recherche Hybride                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  [ON]  ActivÃ©e                                          â”‚
â”‚                                                         â”‚
â”‚  Alpha (Ã©quilibre) :                                    â”‚
â”‚  Mots-clÃ©s â—„â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â–º SÃ©mantique                â”‚
â”‚           0.0    0.5      1.0                           â”‚
â”‚                                                         â”‚
â”‚  â„¹ï¸ Recommandations :                                   â”‚
â”‚  â€¢ Acronymes (RTT, CDI) â†’ Alpha = 0.3                  â”‚
â”‚  â€¢ Questions conceptuelles â†’ Alpha = 0.7               â”‚
â”‚  â€¢ Par dÃ©faut â†’ Alpha = 0.5 (auto)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Explication simple** :
- **Curseur Ã  gauche (0.0)** : Recherche par mots-clÃ©s exacts (comme Google)
- **Curseur au milieu (0.5)** : Ã‰quilibre entre mots-clÃ©s et sens
- **Curseur Ã  droite (1.0)** : Recherche par sens (comprend synonymes)

### 2.3 SystÃ¨me de notation

AprÃ¨s chaque rÃ©ponse, l'utilisateur peut noter avec :

| Action | Signification | Stockage |
|--------|---------------|----------|
| ğŸ‘ Pouce vers le haut | RÃ©ponse utile et prÃ©cise | `rating = 'up'` en base |
| ğŸ‘ Pouce vers le bas | RÃ©ponse incorrecte ou incomplÃ¨te | `rating = 'down'` en base |

**UtilitÃ©** : Ces notes permettent d'identifier les documents Ã  amÃ©liorer ou rÃ©ingÃ©rer.

---

## 3. Interface administrateur

### 3.1 AccÃ¨s Ã  l'interface

L'interface admin est accessible Ã  : `http://localhost:3000/admin`

**Connexion** :
- Seuls les utilisateurs avec `is_admin = true` peuvent y accÃ©der
- Authentification via JWT (token de session)

### 3.2 Upload de documents

L'interface d'upload permet de configurer **3 moteurs indÃ©pendants** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“¤ Upload de Documents                                 â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                         â”‚
â”‚  ğŸ“„ Glissez-dÃ©posez vos fichiers ici                   â”‚
â”‚     ou cliquez pour sÃ©lectionner                        â”‚
â”‚     (PDF, DOCX, MD, TXT, HTML - Max 100MB)            â”‚
â”‚                                                         â”‚
â”‚  âš™ï¸ Configuration d'ingestion :                         â”‚
â”‚                                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”‚
â”‚  â”‚ Moteur OCR   â”‚ Moteur VLM   â”‚ DÃ©coupage    â”‚       â”‚
â”‚  â”‚ (Docling)    â”‚ (Images)     â”‚ (Chunker)    â”‚       â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤       â”‚
â”‚  â”‚ [RapidOCR â–¼] â”‚ [InternVL â–¼] â”‚ [Hybrid â–¼]   â”‚       â”‚
â”‚  â”‚              â”‚              â”‚              â”‚       â”‚
â”‚  â”‚ â€¢ RapidOCR   â”‚ â€¢ InternVL   â”‚ â€¢ Hybrid     â”‚       â”‚
â”‚  â”‚ â€¢ EasyOCR    â”‚ â€¢ PaddleOCR  â”‚ â€¢ Parent-    â”‚       â”‚
â”‚  â”‚ â€¢ Tesseract  â”‚ â€¢ Aucun      â”‚   Child      â”‚       â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â”‚
â”‚                                                         â”‚
â”‚  [Uploader] ğŸš€                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DÃ©tails de configuration** :

| Moteur | Options | Recommandation |
|--------|---------|----------------|
| **OCR** (extraction texte PDF) | RapidOCR, EasyOCR, Tesseract | **RapidOCR** (rapide + multilingue) |
| **VLM** (analyse images) | InternVL, PaddleOCR-VL, Aucun | **InternVL** (meilleure qualitÃ©) |
| **Chunker** (dÃ©coupage) | Hybrid, Parent-Child | **Hybrid** (documents structurÃ©s) |

### 3.3 Gestion des utilisateurs

L'admin peut :
- âœ… CrÃ©er de nouveaux utilisateurs
- âœ… DÃ©finir les droits (admin ou utilisateur standard)
- âœ… Forcer le changement de mot de passe au premier login
- âœ… Voir la liste des conversations par utilisateur

```sql
-- Structure de la table users
CREATE TABLE users (
    id UUID PRIMARY KEY,
    username VARCHAR(100) UNIQUE NOT NULL,
    email VARCHAR(255) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    first_name VARCHAR(100),
    last_name VARCHAR(100),
    is_admin BOOLEAN DEFAULT false,
    must_change_password BOOLEAN DEFAULT false,
    created_at TIMESTAMP DEFAULT NOW()
);
```

### 3.4 Statistiques et monitoring

L'interface admin affiche :

| Statistique | Description | Source |
|-------------|-------------|--------|
| **Documents ingÃ©rÃ©s** | Nombre total de documents | Table `documents` |
| **Chunks crÃ©Ã©s** | Nombre total de morceaux de texte | Table `chunks` |
| **Conversations** | Nombre total de sessions | Table `conversations` |
| **Notes positives/nÃ©gatives** | Ratio de satisfaction | Table `messages` (champ `rating`) |
| **Jobs d'ingestion** | Progression des uploads | Table `ingestion_jobs` |

**Vue temps rÃ©el** :
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“Š Tableau de bord                                     â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚                                                         â”‚
â”‚  ğŸ“„ Documents :  127 documents  |  2,458 chunks        â”‚
â”‚  ğŸ’¬ Conversations :  342 sessions                       â”‚
â”‚  ğŸ‘ Satisfaction :  87% positif  (298/342)             â”‚
â”‚  â±ï¸ Temps moyen :  2.3s par requÃªte                    â”‚
â”‚                                                         â”‚
â”‚  ğŸ”„ Jobs d'ingestion en cours :                        â”‚
â”‚  â€¢ manuel_technique.pdf - 67% â–“â–“â–“â–“â–“â–“â–“â–‘â–‘â–‘              â”‚
â”‚  â€¢ reglement_securite.pdf - 23% â–“â–“â–‘â–‘â–‘â–‘â–‘â–‘â–‘â–‘            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 4. Pipeline d'ingestion des documents

### 4.1 SchÃ©ma complet du pipeline

Voici ce qui se passe **Ã©tape par Ã©tape** quand un document est uploadÃ© :

```mermaid
graph TD
    A[ğŸ“¤ Upload PDF via Admin] --> B{Validation}
    B -->|Type OK, Taille < 100MB| C[ğŸ’¾ Sauvegarde /app/uploads]
    B -->|Erreur| Z[âŒ Rejet avec message]

    C --> D[ğŸ“ CrÃ©ation job dans ingestion_jobs]
    D --> E[â³ Status: pending]

    E --> F[ğŸ”„ Worker dÃ©tecte job<br/>Polling 3s]
    F --> G[ğŸ”§ Claim job<br/>Status: processing]

    G --> H[ğŸ“– Lecture PDF avec Docling]
    H --> I{Moteur OCR sÃ©lectionnÃ©}

    I -->|RapidOCR| J1[ğŸš€ Extraction texte rapide]
    I -->|EasyOCR| J2[ğŸ“š Extraction texte standard]
    I -->|Tesseract| J3[ğŸ” Extraction texte haute qualitÃ©]

    J1 --> K[ğŸ–¼ï¸ DÃ©tection images]
    J2 --> K
    J3 --> K

    K --> L{VLM activÃ© ?}
    L -->|InternVL| M1[ğŸ§  Analyse IA + OCR images<br/>10-15s/image]
    L -->|PaddleOCR-VL| M2[âš¡ OCR local rapide<br/>1-3s/image]
    L -->|None| M3[â­ï¸ Ignore images]

    M1 --> N[ğŸ’¾ Stockage images<br/>/app/uploads/images]
    M2 --> N
    M3 --> N

    N --> O{StratÃ©gie Chunker}
    O -->|Hybrid| P1[âœ‚ï¸ DÃ©coupe respectant<br/>structure document]
    O -->|Parent-Child| P2[ğŸ”— DÃ©coupe hiÃ©rarchique<br/>Parent 2000t + Enfants 600t]

    P1 --> Q[ğŸ§® GÃ©nÃ©ration embeddings<br/>E5-Large 1024 dim]
    P2 --> Q

    Q --> R[ğŸ’¾ Sauvegarde chunks + vectors<br/>PostgreSQL + PGVector]

    R --> S[âœ… Job status: completed<br/>Progress: 100%]
    S --> T[ğŸ‰ Document prÃªt pour recherche]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style H fill:#f3e5f5
    style Q fill:#f3e5f5
    style R fill:#e8f5e9
    style T fill:#c8e6c9
```

### 4.2 Ã‰tapes dÃ©taillÃ©es

#### **Ã‰tape 1 : Upload et validation (Frontend â†’ API)**

**Ce qui se passe** :
1. L'admin glisse-dÃ©pose un PDF dans l'interface
2. Frontend envoie le fichier + configuration (OCR, VLM, Chunker) Ã  l'API
3. API valide :
   - âœ… Type de fichier (PDF, DOCX, MD, TXT, HTML)
   - âœ… Taille < 100MB
   - âœ… Moteurs sÃ©lectionnÃ©s valides

**Stockage** :
```
/app/uploads/
  â””â”€â”€ {job_id}/
      â””â”€â”€ document.pdf  (fichier original)
```

**Base de donnÃ©es** :
```sql
INSERT INTO ingestion_jobs (
    id,
    filename,
    status,           -- 'pending'
    ocr_engine,       -- 'rapidocr', 'easyocr', 'tesseract'
    vlm_engine,       -- 'internvl', 'paddleocr-vl', 'none'
    chunker_type,     -- 'hybrid', 'parent_child'
    created_at
) VALUES (
    '123e4567-...',
    'manuel_technique.pdf',
    'pending',
    'rapidocr',
    'internvl',
    'hybrid',
    NOW()
);
```

#### **Ã‰tape 2 : DÃ©tection par le Worker**

**Ce qui se passe** :
1. Le Worker (service sÃ©parÃ©) interroge la base toutes les **3 secondes**
2. Il cherche les jobs avec `status = 'pending'`
3. DÃ¨s qu'il en trouve un, il le "rÃ©clame" (claim) :

```sql
UPDATE ingestion_jobs
SET status = 'processing', started_at = NOW()
WHERE id = '123e4567-...'
```

**Pourquoi un Worker sÃ©parÃ© ?**
- âœ… Ne bloque pas l'API (traitement asynchrone)
- âœ… Peut traiter plusieurs jobs en parallÃ¨le
- âœ… Facile Ã  redÃ©marrer en cas d'erreur
- âœ… Partage le volume `/app/uploads` avec l'API

#### **Ã‰tape 3 : Extraction de texte (Docling + OCR)**

**Ce qui se passe** :
1. Le Worker lit le PDF avec **Docling** (bibliothÃ¨que avancÃ©e)
2. Docling utilise le moteur OCR sÃ©lectionnÃ© :

| Moteur | Vitesse | QualitÃ© | Meilleur pour |
|--------|---------|---------|---------------|
| **RapidOCR** | âš¡âš¡âš¡ Rapide (~2s/page) | â­â­â­ Excellente | PDFs modernes, multilingue |
| **EasyOCR** | âš¡âš¡ Standard (~4s/page) | â­â­â­ Excellente | Fallback robuste |
| **Tesseract** | âš¡ Lent (~6s/page) | â­â­â­â­ TrÃ¨s haute | Scans anciens, documents archivÃ©s |

**Exemple de sortie** :
```
Page 1: "Introduction\nCe manuel technique dÃ©crit..."
Page 2: "Chapitre 1 : Configuration\n1.1 PrÃ©requis..."
...
```

**MÃ©tadonnÃ©es extraites** :
- Nombre de pages
- Titre (si prÃ©sent dans mÃ©tadonnÃ©es PDF)
- Auteur (si prÃ©sent)
- Date de crÃ©ation

#### **Ã‰tape 4 : Extraction d'images (VLM)**

**Ce qui se passe** :
1. Docling dÃ©tecte automatiquement les images dans le PDF
2. Pour chaque image dÃ©tectÃ©e :
   - Extraction de l'image (PNG)
   - DÃ©tection de la position (page, x, y, largeur, hauteur)
   - Filtrage (ignore petites icÃ´nes < 200x200px)
3. Si VLM activÃ©, analyse de l'image :

**Moteur InternVL** (API distant) :
```
ğŸ§  Analyse IA complÃ¨te :
â€¢ Description sÃ©mantique : "Ce diagramme montre le processus..."
â€¢ OCR du texte visible : "Ã‰tape 1 â†’ Validation â†’ Ã‰tape 2"
â€¢ Confiance : 0.92
â€¢ Temps : ~10-15s/image
```

**Moteur PaddleOCR-VL** (local) :
```
âš¡ Analyse rapide :
â€¢ OCR multilingue (109 langues)
â€¢ DÃ©tection de layout (colonnes, tableaux)
â€¢ Description structurelle basique
â€¢ Temps : ~1-3s/image
```

**Stockage** :
```
/app/uploads/images/
  â””â”€â”€ {job_id}/
      â”œâ”€â”€ image_001.png  (diagramme page 3)
      â”œâ”€â”€ image_002.png  (tableau page 5)
      â””â”€â”€ ...
```

**Base de donnÃ©es** :
```sql
INSERT INTO document_images (
    id,
    document_id,
    chunk_id,           -- LiÃ© au chunk de la mÃªme page
    page_number,        -- 3
    position,           -- {"x": 100, "y": 200, "width": 400, "height": 300}
    image_path,         -- '/app/uploads/images/{job_id}/image_001.png'
    image_base64,       -- 'data:image/png;base64,iVBORw0KG...' (pour affichage)
    description,        -- 'Ce diagramme montre...'
    ocr_text,           -- 'Ã‰tape 1 â†’ Validation â†’ Ã‰tape 2'
    confidence_score    -- 0.92
);
```

#### **Ã‰tape 5 : DÃ©coupage en chunks**

**Analogie** : Imaginez un livre de 200 pages. Pour faciliter la recherche, on le dÃ©coupe en **sections logiques** (chapitres, sous-sections). C'est le rÃ´le du Chunker.

**Deux stratÃ©gies disponibles** (dÃ©taillÃ©es dans section 5) :

**Hybrid Chunker** (recommandÃ© pour documents structurÃ©s) :
- Respecte la structure du document (titres, paragraphes, tableaux)
- Taille variable selon le contenu (~1500 tokens)
- Ne coupe jamais un paragraphe ou un tableau en deux

**Parent-Child Chunker** (pour longs textes continus) :
- CrÃ©e des chunks parents (2000 tokens) pour le contexte
- Les dÃ©coupe en chunks enfants (600 tokens) pour la recherche
- Optimal pour transcriptions, interviews, romans

**MÃ©tadonnÃ©es ajoutÃ©es Ã  chaque chunk** :
```json
{
  "section_hierarchy": ["Chapitre 1", "1.2 Configuration", "1.2.1 PrÃ©requis"],
  "heading_context": "1.2.1 PrÃ©requis",
  "document_position": 0.15,  // 15% du document
  "prev_chunk_id": "abc-123",
  "next_chunk_id": "def-456",
  "page_number": 3
}
```

#### **Ã‰tape 6 : GÃ©nÃ©ration des embeddings**

**Qu'est-ce qu'un embedding ?**

> **Analogie** : Imaginez que chaque morceau de texte est transformÃ© en une "empreinte digitale" mathÃ©matique. Cette empreinte capture le **sens** du texte, pas juste les mots.

**Exemple concret** :
```
Texte 1 : "La procÃ©dure de tÃ©lÃ©travail"
Embedding : [0.23, -0.45, 0.78, ..., 0.12]  (1024 nombres)

Texte 2 : "Le rÃ¨glement du travail Ã  distance"
Embedding : [0.21, -0.43, 0.80, ..., 0.14]  (trÃ¨s proche !)

Texte 3 : "La recette du gÃ¢teau au chocolat"
Embedding : [-0.89, 0.12, -0.34, ..., 0.56]  (trÃ¨s diffÃ©rent)
```

**ModÃ¨le utilisÃ©** : **E5-Large** (multilingual)
- Dimension : 1024 nombres par embedding
- Multilingue : FranÃ§ais, Anglais, Allemand, Espagnol...
- QualitÃ© : Ã‰tat de l'art pour le franÃ§ais

**Processus** :
1. Le Worker envoie les chunks au service Embeddings (port 8001)
2. Traitement par batch de **20 chunks** Ã  la fois (optimisation)
3. RÃ©ception des vecteurs 1024-dim
4. Timeout : 90 secondes (documents trÃ¨s longs)

#### **Ã‰tape 7 : Sauvegarde en base de donnÃ©es**

**Ce qui est stockÃ©** :

```sql
-- Table documents
INSERT INTO documents (
    id,
    title,              -- 'manuel_technique.pdf'
    source,             -- '/app/uploads/{job_id}/manuel_technique.pdf'
    metadata,           -- {"pages": 42, "author": "Service RH"}
    created_at
);

-- Table chunks (pour chaque morceau)
INSERT INTO chunks (
    id,
    document_id,        -- Lien vers le document parent
    content,            -- Le texte du chunk
    embedding,          -- vector(1024) - l'empreinte mathÃ©matique
    chunk_index,        -- Position dans le document (0, 1, 2, ...)
    metadata,           -- MÃ©tadonnÃ©es spÃ©cifiques

    -- MÃ©tadonnÃ©es structurelles (Phase 2.1)
    prev_chunk_id,      -- Chunk prÃ©cÃ©dent (contexte)
    next_chunk_id,      -- Chunk suivant (contexte)
    section_hierarchy,  -- ["Chapitre 1", "1.2 Config"]
    heading_context,    -- "1.2 Configuration"
    document_position,  -- 0.15 (15% du doc)

    -- MÃ©tadonnÃ©es hiÃ©rarchiques (Phase 2.3)
    chunk_level,        -- 'parent' ou 'child'
    parent_chunk_id,    -- Si child, lien vers parent

    -- MÃ©tadonnÃ©es gÃ©nÃ©rales
    token_count,        -- Nombre de tokens
    page_number,        -- NumÃ©ro de page
    created_at
);
```

**Liens Ã©tablis** :
1. Chunks â†’ Document (via `document_id`)
2. Chunks â†’ Chunks prÃ©cÃ©dents/suivants (via `prev_chunk_id`, `next_chunk_id`)
3. Chunks enfants â†’ Chunks parents (via `parent_chunk_id`)
4. Images â†’ Chunks (via `chunk_id` + `page_number`)

#### **Ã‰tape 8 : Finalisation**

**Ce qui se passe** :
1. Worker met Ã  jour le job :
```sql
UPDATE ingestion_jobs
SET
    status = 'completed',
    progress = 100,
    chunks_created = 127,
    completed_at = NOW()
WHERE id = '123e4567-...';
```

2. Frontend interroge l'API toutes les **2 secondes** pour le statut
3. DÃ¨s que `status = 'completed'`, document apparaÃ®t dans l'interface admin
4. Le document est **immÃ©diatement recherchable** par les utilisateurs

**DurÃ©e totale typique** :
- PDF 10 pages, Hybrid, RapidOCR, sans images : **~15-20 secondes**
- PDF 50 pages, Hybrid, RapidOCR, 10 images avec InternVL : **~3-4 minutes**
- PDF 200 pages, Parent-Child, Tesseract, 50 images : **~15-20 minutes**

---

## 5. StratÃ©gies de dÃ©coupage (Chunking)

### 5.1 Pourquoi dÃ©couper les documents ?

**ProblÃ¨me** : Un document de 100 pages ne peut pas Ãªtre envoyÃ© en entier au modÃ¨le d'IA (limite de tokens).

**Solution** : DÃ©couper en **morceaux (chunks)** plus petits, puis chercher les plus pertinents.

**Analogie** : Au lieu de lire un livre entier pour rÃ©pondre Ã  une question, on consulte seulement les chapitres pertinents.

### 5.2 Hybrid Chunker (par dÃ©faut)

#### **Principe**

Le Hybrid Chunker **respecte la structure logique du document** :
- Ne coupe jamais un paragraphe en deux
- Garde les tableaux entiers
- Respecte les sections et sous-sections
- PrÃ©serve les listes Ã  puces

#### **SchÃ©ma de fonctionnement**

```mermaid
graph LR
    A[Document complet] --> B[Docling analyse structure]
    B --> C{Type de bloc}

    C -->|Paragraphe| D[Chunk entier<br/>~500-800 tokens]
    C -->|Tableau| E[Chunk entier<br/>~200-1500 tokens]
    C -->|Liste| F[Chunk entier<br/>~300-600 tokens]
    C -->|Section courte| G[Chunk entier<br/>~400-1000 tokens]
    C -->|Section longue| H[DÃ©coupe par<br/>sous-sections]

    D --> I[Chunks finaux]
    E --> I
    F --> I
    G --> I
    H --> I

    I --> J[Overlap 200 tokens<br/>entre chunks adjacents]

    style A fill:#e3f2fd
    style B fill:#fff3e0
    style I fill:#e8f5e9
    style J fill:#c8e6c9
```

#### **Exemple concret**

**Document source** :
```
Chapitre 1 : Configuration du systÃ¨me
1.1 PrÃ©requis
Pour installer le logiciel, vous devez disposer de :
- Windows 10 ou supÃ©rieur
- 8 GB de RAM minimum
- 20 GB d'espace disque

1.2 Installation
Suivez ces Ã©tapes pour installer le logiciel :
1. TÃ©lÃ©chargez le fichier d'installation
2. ExÃ©cutez setup.exe avec droits admin
3. Suivez l'assistant d'installation
[... 500 mots supplÃ©mentaires ...]

1.3 Configuration post-installation
[... contenu ...]
```

**RÃ©sultat du dÃ©coupage Hybrid** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 1 (document_position: 0.00-0.08)                 â”‚
â”‚ Section: ["Chapitre 1", "1.1 PrÃ©requis"]              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Chapitre 1 : Configuration du systÃ¨me                  â”‚
â”‚ 1.1 PrÃ©requis                                          â”‚
â”‚ Pour installer le logiciel, vous devez disposer de :   â”‚
â”‚ - Windows 10 ou supÃ©rieur                              â”‚
â”‚ - 8 GB de RAM minimum                                  â”‚
â”‚ - 20 GB d'espace disque                                â”‚
â”‚                                                         â”‚
â”‚ Metadata:                                               â”‚
â”‚ â€¢ prev_chunk_id: null                                   â”‚
â”‚ â€¢ next_chunk_id: chunk-002                              â”‚
â”‚ â€¢ heading_context: "1.1 PrÃ©requis"                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk 2 (document_position: 0.08-0.45)                 â”‚
â”‚ Section: ["Chapitre 1", "1.2 Installation"]           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ [Overlap 200 tokens du chunk 1]                        â”‚
â”‚                                                         â”‚
â”‚ 1.2 Installation                                        â”‚
â”‚ Suivez ces Ã©tapes pour installer le logiciel :         â”‚
â”‚ 1. TÃ©lÃ©chargez le fichier d'installation              â”‚
â”‚ 2. ExÃ©cutez setup.exe avec droits admin               â”‚
â”‚ 3. Suivez l'assistant d'installation                   â”‚
â”‚ [... reste du contenu ...]                             â”‚
â”‚                                                         â”‚
â”‚ Metadata:                                               â”‚
â”‚ â€¢ prev_chunk_id: chunk-001                              â”‚
â”‚ â€¢ next_chunk_id: chunk-003                              â”‚
â”‚ â€¢ heading_context: "1.2 Installation"                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- âœ… **Contexte prÃ©servÃ©** : Chaque chunk a du sens seul
- âœ… **Structure claire** : On sait toujours dans quelle section on est
- âœ… **Tableaux intacts** : Pas de tableaux coupÃ©s en deux
- âœ… **Overlap intelligent** : 200 tokens partagÃ©s entre chunks adjacents

**InconvÃ©nients** :
- âš ï¸ **Taille variable** : Chunks de 300 Ã  2000 tokens (selon structure)
- âš ï¸ **Peut couper sections longues** : Si une section fait 5000 tokens

### 5.3 Parent-Child Chunker (pour textes longs)

#### **Principe**

Le Parent-Child Chunker crÃ©e une **architecture Ã  deux niveaux** :
1. **Chunks parents** (2000 tokens) : Contexte riche pour le LLM
2. **Chunks enfants** (600 tokens) : PrÃ©cision pour la recherche

**Analogie** : C'est comme un livre avec des chapitres (parents) divisÃ©s en paragraphes (enfants). On cherche dans les paragraphes, mais on lit les chapitres complets.

#### **SchÃ©ma de fonctionnement**

```mermaid
graph TB
    A[Document complet<br/>10,000 tokens] --> B[DÃ©coupe en Parents<br/>~2000 tokens chacun]

    B --> C[Parent 1<br/>tokens 0-2000]
    B --> D[Parent 2<br/>tokens 2000-4000]
    B --> E[Parent 3<br/>tokens 4000-6000]
    B --> F[...]

    C --> G[Child 1.1<br/>tokens 0-600]
    C --> H[Child 1.2<br/>tokens 600-1200]
    C --> I[Child 1.3<br/>tokens 1200-1800]

    D --> J[Child 2.1<br/>tokens 2000-2600]
    D --> K[Child 2.2<br/>tokens 2600-3200]
    D --> L[Child 2.3<br/>tokens 3200-3800]

    style A fill:#e3f2fd
    style C fill:#fff3e0
    style D fill:#fff3e0
    style E fill:#fff3e0
    style G fill:#e8f5e9
    style H fill:#e8f5e9
    style I fill:#e8f5e9
    style J fill:#e8f5e9
    style K fill:#e8f5e9
    style L fill:#e8f5e9
```

#### **Comment Ã§a marche en pratique ?**

**Lors de l'ingestion** :
1. Document dÃ©coupÃ© en chunks parents (2000 tokens)
2. Chaque parent dÃ©coupÃ© en 3-5 enfants (600 tokens)
3. Stockage en base :
   - Parents : `chunk_level = 'parent'`
   - Enfants : `chunk_level = 'child'` + `parent_chunk_id = {uuid_parent}`

**Lors de la recherche** :
1. Recherche vectorielle opÃ¨re sur les **enfants** (plus prÃ©cis)
2. Les enfants trouvÃ©s renvoient leurs **parents** (contexte riche)
3. Le LLM reÃ§oit les parents complets (2000 tokens)

#### **Exemple concret**

**Document source** : Transcription d'interview (20,000 tokens)

**Stockage** :

```sql
-- Parent 1
INSERT INTO chunks (
    id = 'parent-001',
    content = '[10 minutes de conversation complÃ¨te]',  -- 2000 tokens
    chunk_level = 'parent',
    parent_chunk_id = null
);

-- Enfants du Parent 1
INSERT INTO chunks (
    id = 'child-001-1',
    content = '[2 premiÃ¨res minutes]',  -- 600 tokens
    chunk_level = 'child',
    parent_chunk_id = 'parent-001'
);

INSERT INTO chunks (
    id = 'child-001-2',
    content = '[Minutes 2-4]',  -- 600 tokens
    chunk_level = 'child',
    parent_chunk_id = 'parent-001'
);

-- ... etc pour les autres enfants
```

**Lors d'une recherche** :

```
Question : "Que pense le candidat de la flexibilitÃ© ?"

1. Recherche vectorielle trouve :
   â€¢ child-001-3 (score: 0.87) - "Je valorise la flexibilitÃ©..."
   â€¢ child-003-1 (score: 0.82) - "...Ã©quilibre vie pro/perso..."

2. SystÃ¨me rÃ©cupÃ¨re les parents correspondants :
   â€¢ parent-001 (contexte : 2000 tokens autour de la flexibilitÃ©)
   â€¢ parent-003 (contexte : 2000 tokens sur Ã©quilibre)

3. LLM reÃ§oit les parents complets â†’ RÃ©ponse riche en contexte
```

**Avantages** :
- âœ… **Meilleure prÃ©cision** : Recherche sur petits chunks (600t)
- âœ… **Contexte riche** : LLM reÃ§oit gros chunks (2000t)
- âœ… **Moins de hallucination** : Plus d'information autour du passage trouvÃ©

**InconvÃ©nients** :
- âš ï¸ **Plus de stockage** : 3-5x plus de chunks (parents + enfants)
- âš ï¸ **Peut couper sections** : Ne respecte pas toujours la structure logique
- âš ï¸ **Ingestion plus lente** : +20-30% de temps de traitement

### 5.4 Tableau comparatif

| CritÃ¨re | Hybrid Chunker | Parent-Child Chunker |
|---------|----------------|----------------------|
| **Type de document** | Documents structurÃ©s (manuels, rapports) | Textes longs continus (interviews, transcriptions) |
| **Respect de la structure** | âœ… Oui (sections, tableaux intacts) | âš ï¸ Partiel (peut couper sections) |
| **Taille des chunks** | Variable (300-2000 tokens) | Fixe (Parents: 2000t, Enfants: 600t) |
| **Stockage** | 1x (chunks normaux) | 3-5x (parents + enfants) |
| **Temps d'ingestion** | Standard (baseline) | +20-30% |
| **QualitÃ© recherche** | â­â­â­ Bonne | â­â­â­â­ Excellente (prÃ©cision) |
| **Contexte LLM** | â­â­â­ Bon | â­â­â­â­ TrÃ¨s riche |
| **Migration requise** | âŒ Non (par dÃ©faut) | âœ… Oui (migration 06) |

### 5.5 Quand utiliser l'un ou l'autre ?

**Utilisez Hybrid Chunker pour** :
- ğŸ“š Manuels techniques
- ğŸ“Š Rapports avec tableaux et graphiques
- ğŸ“‹ Documentation structurÃ©e (API, procÃ©dures)
- ğŸ¥ Protocoles mÃ©dicaux (Ã©tapes sÃ©quentielles)
- ğŸ“‘ Contrats juridiques (articles, clauses)

**Utilisez Parent-Child Chunker pour** :
- ğŸ™ï¸ Transcriptions d'interviews
- ğŸ“– Chapitres de livres (longs textes narratifs)
- ğŸ’¬ Conversations / dialogues
- ğŸ“ Articles de blog / essais (peu structurÃ©s)
- ğŸ¬ Sous-titres de vidÃ©os

**Conseil pratique** :
> Commencez toujours avec **Hybrid** (dÃ©faut). Si les rÃ©sultats de recherche manquent de contexte ou si le document est trÃ¨s long et peu structurÃ©, testez **Parent-Child** sur le mÃªme document et comparez.

---

## 6. SystÃ¨me de recherche

### 6.1 Vue d'ensemble des types de recherche

RAGFab propose **3 modes de recherche** combinables :

```mermaid
graph TB
    Q[â“ Question utilisateur] --> A{Mode recherche}

    A -->|Mode 1| B[ğŸ”µ Recherche Vectorielle<br/>SÃ©mantique seule]
    A -->|Mode 2| C[ğŸŸ£ Recherche Hybride<br/>Vectorielle + Mots-clÃ©s]
    A -->|Mode 3| D[ğŸ”´ Reranking activÃ©<br/>+ CrossEncoder]

    B --> E[RÃ©sultats top-5]
    C --> F[Fusion RRF top-5]

    E --> G{Reranking ?}
    F --> G

    G -->|Non| H[RÃ©sultats finaux]
    G -->|Oui| D

    D --> I[Top-20 candidats]
    I --> J[CrossEncoder analyse]
    J --> K[RÃ©sultats top-5 affinÃ©s]

    H --> L[ğŸ¤– LLM gÃ©nÃ¨re rÃ©ponse]
    K --> L

    style B fill:#e3f2fd
    style C fill:#f3e5f5
    style D fill:#ffebee
    style L fill:#e8f5e9
```

### 6.2 Recherche vectorielle (sÃ©mantique)

#### **Comment Ã§a marche ?**

**Analogie** : Imaginez une bibliothÃ¨que oÃ¹ chaque livre a une "empreinte digitale" mathÃ©matique. Pour trouver un livre, on compare l'empreinte de votre question avec celles des livres, et on prend les plus proches.

**Processus technique** :

```mermaid
sequenceDiagram
    participant U as Utilisateur
    participant API as Web API
    participant E as Service Embeddings
    participant DB as PostgreSQL

    U->>API: "Quelle est la procÃ©dure RTT ?"
    API->>E: GÃ©nÃ¨re embedding de la question
    E-->>API: vector(1024) [0.23, -0.45, ...]
    API->>DB: SELECT * FROM match_chunks(...)<br/>ORDER BY cosine_distance
    DB-->>API: Top-5 chunks les plus proches
    API->>API: RÃ©cupÃ©ration chunks adjacents<br/>(prev + next pour contexte)
    API->>U: Chunks + metadata + scores
```

**Fonction SQL utilisÃ©e** :
```sql
SELECT
    c.id,
    c.content,
    c.metadata,
    c.section_hierarchy,
    c.heading_context,
    (1 - (c.embedding <=> $1)) AS similarity_score,  -- Cosine similarity
    d.title AS document_title,
    d.source AS document_source
FROM chunks c
JOIN documents d ON c.document_id = d.id
ORDER BY c.embedding <=> $1  -- <=> = cosine distance
LIMIT 5;
```

**Exemple concret** :

```
Question : "procÃ©dure de tÃ©lÃ©travail"
â†’ Embedding : [0.23, -0.45, 0.78, ..., 0.12]

Chunk 1 : "La procÃ©dure de travail Ã  distance..."
â†’ Embedding : [0.21, -0.43, 0.80, ..., 0.14]
â†’ Distance cosine : 0.12 â†’ SimilaritÃ© : 0.88 âœ…

Chunk 2 : "Le rÃ¨glement concernant le remote work..."
â†’ Embedding : [0.19, -0.40, 0.82, ..., 0.16]
â†’ Distance cosine : 0.18 â†’ SimilaritÃ© : 0.82 âœ…

Chunk 3 : "Les horaires d'ouverture de la cantine..."
â†’ Embedding : [-0.67, 0.23, -0.12, ..., 0.45]
â†’ Distance cosine : 0.89 â†’ SimilaritÃ© : 0.11 âŒ
```

**Forces** :
- âœ… Comprend les **synonymes** (tÃ©lÃ©travail = remote work = travail Ã  distance)
- âœ… Capture le **sens** au-delÃ  des mots exacts
- âœ… Multilingue (franÃ§ais/anglais mÃ©langÃ©s)

**Faiblesses** :
- âŒ Peut rater les **acronymes** (RTT, CDI, PeopleDoc)
- âŒ Peut rater les **noms propres** (logiciels, marques)
- âŒ Moins prÃ©cis sur **termes techniques rares**

### 6.3 RÃ©cupÃ©ration des chunks adjacents

**ProblÃ¨me rÃ©solu** : Un chunk seul peut manquer de contexte.

**Solution** : Pour chaque chunk trouvÃ©, rÃ©cupÃ©rer aussi le chunk **prÃ©cÃ©dent** et **suivant**.

**Exemple** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Chunk trouvÃ© (score: 0.89)                             â”‚
â”‚ Section: ["Chapitre 2", "2.3 TÃ©lÃ©travail"]            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ â¬†ï¸ Contexte prÃ©cÃ©dent (prev_chunk_id):                 â”‚
â”‚ "...conditions d'Ã©ligibilitÃ© au tÃ©lÃ©travail..."        â”‚
â”‚                                                         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ ğŸ“ CHUNK PRINCIPAL (celui qui match):                  â”‚
â”‚ "La procÃ©dure de demande de tÃ©lÃ©travail se fait        â”‚
â”‚  via le portail RH. Le salariÃ© doit soumettre..."      â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚                                                         â”‚
â”‚ â¬‡ï¸ Contexte suivant (next_chunk_id):                   â”‚
â”‚ "...validation par le manager dans les 48h..."         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Activation** : Variable d'environnement
```bash
USE_ADJACENT_CHUNKS=true  # RecommandÃ© (latence nÃ©gligeable)
```

**Impact** :
- â±ï¸ Latence : +5-20ms (1 seule requÃªte SQL avec JOIN)
- ğŸ’¾ Tokens : +300-900 tokens par rÃ©sultat (prev + next)
- ğŸ“ˆ QualitÃ© : +15-25% de pertinence (estimation)

### 6.4 Fonction de recherche intelligente

RAGFab utilise une fonction PostgreSQL avancÃ©e qui gÃ¨re **automatiquement** les chunks parents/enfants :

```sql
CREATE FUNCTION match_chunks_smart(
    query_embedding vector(1024),
    match_count INT DEFAULT 5
)
RETURNS TABLE(...) AS $
BEGIN
    -- DÃ©tection automatique : Y a-t-il des chunks parent-child ?
    IF EXISTS (SELECT 1 FROM chunks WHERE chunk_level = 'child') THEN
        -- Mode parent-child : Cherche dans enfants, retourne parents
        RETURN QUERY
        SELECT DISTINCT p.*
        FROM chunks c
        JOIN chunks p ON c.parent_chunk_id = p.id
        WHERE c.chunk_level = 'child'
        ORDER BY c.embedding <=> query_embedding
        LIMIT match_count;
    ELSE
        -- Mode standard : Recherche directe
        RETURN QUERY
        SELECT *
        FROM chunks
        ORDER BY embedding <=> query_embedding
        LIMIT match_count;
    END IF;
END;
$ LANGUAGE plpgsql;
```

**Avantage** : Pas besoin de savoir quel type de chunking a Ã©tÃ© utilisÃ©. La fonction s'adapte automatiquement.

---

## 7. Recherche hybride en dÃ©tail

### 7.1 Pourquoi la recherche hybride ?

**ProblÃ¨me identifiÃ©** : La recherche vectorielle (sÃ©mantique) peut rater des termes spÃ©cifiques.

**Cas problÃ©matiques** :
- **Acronymes** : RTT, CDI, PeopleDoc, SIRH
- **Noms propres** : Noms de logiciels, marques, personnes
- **Termes techniques** : Nomenclatures, codes, rÃ©fÃ©rences
- **Expressions exactes** : "congÃ©s payÃ©s", "rupture conventionnelle"

**Exemple rÃ©el** :

```
âŒ AVANT (vectorielle seule) :
Question : "procÃ©dure RTT"
â†’ Trouve : Documents sur "temps de travail", "horaires", "planning"
â†’ Rate : Le document spÃ©cifique avec l'acronyme "RTT"

âœ… APRÃˆS (hybride) :
Question : "procÃ©dure RTT"
â†’ Trouve : Documents contenant explicitement "RTT" ET similaires sÃ©mantiquement
â†’ Score combinÃ© = 70% sÃ©mantique + 30% mots-clÃ©s
```

### 7.2 Analogie simple : La bibliothÃ¨que

**Recherche vectorielle** = Demander au bibliothÃ©caire "Parlez-moi de livres sur les voyages"
- Il comprend le **sens** et vous propose des livres sur l'aventure, l'exploration, le tourisme

**Recherche par mots-clÃ©s** = Chercher dans le catalogue "Livres contenant le mot 'Madagascar'"
- Recherche **littÃ©rale**, trouve exactement ce mot

**Recherche hybride** = Les deux combinÃ©s avec un curseur :
- **Curseur Ã  gauche (alpha=0.3)** : "Je veux d'abord les livres avec 'Madagascar', puis ceux sur les voyages"
- **Curseur au milieu (alpha=0.5)** : "Ã‰quilibre entre 'Madagascar' exact et livres sur voyages exotiques"
- **Curseur Ã  droite (alpha=0.7)** : "PrivilÃ©gie le sens gÃ©nÃ©ral 'voyages', mais boost si 'Madagascar' apparaÃ®t"

### 7.3 Comment Ã§a fonctionne techniquement ?

#### **RRF (Reciprocal Rank Fusion)**

**Principe** : Combiner deux listes de rÃ©sultats en une seule, en respectant un Ã©quilibre.

**Formule mathÃ©matique** :
```
score_combinÃ© = alpha Ã— (1 / (k + rang_vectoriel))
              + (1 - alpha) Ã— (1 / (k + rang_mots_clÃ©s))

OÃ¹ :
â€¢ k = 60 (constante RRF standard pour stabilitÃ©)
â€¢ alpha = poids entre 0.0 et 1.0
â€¢ rang = position dans la liste (1er = 1, 2e = 2, etc.)
```

**Exemple concret** :

```
Question : "procÃ©dure RTT"
Alpha : 0.5 (Ã©quilibre)

RÃ©sultats recherche VECTORIELLE :
1. doc_A (score vector: 0.89)
2. doc_B (score vector: 0.82)
3. doc_C (score vector: 0.78)
4. doc_D (score vector: 0.71)
5. doc_E (score vector: 0.68)

RÃ©sultats recherche MOTS-CLÃ‰S (BM25) :
1. doc_D (contient "RTT" 5 fois)
2. doc_A (contient "RTT" 2 fois)
3. doc_F (contient "RTT" 1 fois)
4. doc_B (contient "procÃ©dure" 3 fois)
5. doc_G (contient "procÃ©dure" 2 fois)

Calcul RRF pour doc_A :
â€¢ rang_vectoriel = 1
â€¢ rang_mots_clÃ©s = 2
â€¢ score_combinÃ© = 0.5 Ã— (1/(60+1)) + 0.5 Ã— (1/(60+2))
â€¢               = 0.5 Ã— 0.0164 + 0.5 Ã— 0.0161
â€¢               = 0.0163

Calcul RRF pour doc_D :
â€¢ rang_vectoriel = 4
â€¢ rang_mots_clÃ©s = 1
â€¢ score_combinÃ© = 0.5 Ã— (1/(60+4)) + 0.5 Ã— (1/(60+1))
â€¢               = 0.5 Ã— 0.0156 + 0.5 Ã— 0.0164
â€¢               = 0.0160

CLASSEMENT FINAL HYBRIDE :
1. doc_A (0.0163) â† Meilleur Ã©quilibre
2. doc_D (0.0160) â† Bon sur mots-clÃ©s, moyen sur sÃ©mantique
3. doc_B (0.0154)
4. doc_C (0.0148)
5. doc_F (0.0142)
```

#### **Preprocessing de la requÃªte**

Avant la recherche par mots-clÃ©s, la requÃªte est **nettoyÃ©e** :

**Ã‰tapes** :
1. **Suppression des stopwords franÃ§ais** (130+ mots) :
   - Avant : "Quelle est la procÃ©dure pour demander le RTT ?"
   - AprÃ¨s : "procÃ©dure demander RTT"

2. **PrÃ©servation des Ã©lÃ©ments importants** :
   - Acronymes (2+ lettres maj) : RTT, CDI, PeopleDoc âœ…
   - Noms propres (maj aprÃ¨s 1er mot) : "logiciel PeopleDoc" âœ…
   - Nombres : 2024, 30%, 15 jours âœ…

3. **Conversion en tsquery PostgreSQL** :
   - "procÃ©dure demander RTT" â†’ `procÃ©dure & demander & RTT`
   - OpÃ©rateur AND implicite entre mots

**Code Python** :
```python
def preprocess_query_for_tsquery(query: str) -> str:
    # Stopwords franÃ§ais
    stopwords = ["le", "la", "les", "un", "une", "de", "du", "des", ...]

    # Tokenize
    words = query.split()

    # Garde : acronymes, noms propres, mots significatifs
    filtered = [
        word for word in words
        if word.lower() not in stopwords
        or re.match(r'^[A-Z]{2,}$', word)  # Acronymes
    ]

    # Combine avec &
    return " & ".join(filtered)
```

#### **Calcul alpha adaptatif**

RAGFab ajuste **automatiquement** l'alpha selon le type de question :

```python
def adaptive_alpha(query: str) -> float:
    """
    Retourne l'alpha optimal selon la nature de la requÃªte.
    """
    query_lower = query.lower()
    words = query.split()

    # CAS 1 : Acronymes dÃ©tectÃ©s â†’ Bias mots-clÃ©s
    if re.search(r'\b[A-Z]{2,}\b', query):
        return 0.3  # 30% sÃ©mantique, 70% mots-clÃ©s

    # CAS 2 : Noms propres (maj aprÃ¨s 1er mot) â†’ Bias mots-clÃ©s
    proper_nouns = [w for w in words[1:] if w[0].isupper()]
    if proper_nouns:
        return 0.3

    # CAS 3 : Questions conceptuelles â†’ Bias sÃ©mantique
    conceptual = ["pourquoi", "comment", "expliquer", "signifie"]
    if any(kw in query_lower for kw in conceptual):
        return 0.7  # 70% sÃ©mantique, 30% mots-clÃ©s

    # CAS 4 : Questions courtes (â‰¤4 mots) â†’ LÃ©ger bias mots-clÃ©s
    if len(words) <= 4:
        return 0.4

    # CAS 5 : Par dÃ©faut â†’ Ã‰quilibre
    return 0.5
```

**Exemples d'alpha adaptatif** :

| Question | Alpha calculÃ© | Raison |
|----------|---------------|--------|
| "procÃ©dure RTT" | 0.3 | Acronyme dÃ©tectÃ© |
| "logiciel PeopleDoc" | 0.3 | Nom propre dÃ©tectÃ© |
| "Pourquoi favoriser le tÃ©lÃ©travail ?" | 0.7 | Question conceptuelle |
| "congÃ©s payÃ©s" | 0.4 | Question courte (2 mots) |
| "Quelle est la procÃ©dure de demande de tÃ©lÃ©travail ?" | 0.5 | Question standard |

### 7.4 Interface utilisateur : Le curseur alpha

**Affichage dans le frontend** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ”€ Recherche Hybride                                   â”‚
â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚  [ON]  ActivÃ©e                                          â”‚
â”‚                                                         â”‚
â”‚  Ajuster l'Ã©quilibre :                                  â”‚
â”‚  Mots-clÃ©s â—„â”€â”€â”€â”€â”€â”€â—â”€â”€â”€â”€â”€â”€â”€â”€â–º SÃ©mantique                â”‚
â”‚           0.0    0.5      1.0                           â”‚
â”‚           â†‘ (actuel: auto)                              â”‚
â”‚                                                         â”‚
â”‚  ğŸ’¡ Exemples d'utilisation :                            â”‚
â”‚  â€¢ Acronymes (RTT, CDI) â†’ 0.3 (auto)                   â”‚
â”‚  â€¢ Questions de sens â†’ 0.7 (auto)                      â”‚
â”‚  â€¢ Forcer mots-clÃ©s â†’ DÃ©placer vers 0.0               â”‚
â”‚                                                         â”‚
â”‚  â„¹ï¸ Mode AUTO activÃ© : L'alpha s'adapte automatiquementâ”‚
â”‚     Ã  votre question. DÃ©placez le curseur pour forcer  â”‚
â”‚     un Ã©quilibre manuel.                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Comportement** :
1. **Par dÃ©faut** : Mode AUTO (curseur grisÃ©, alpha calculÃ© automatiquement)
2. **DÃ©placement manuel** : DÃ©sactive AUTO, alpha fixÃ© par l'utilisateur
3. **RÃ©initialisation** : Bouton "AUTO" pour revenir au mode adaptatif

### 7.5 BM25 : L'algorithme de mots-clÃ©s

**Qu'est-ce que BM25 ?**

> BM25 (Best Matching 25) est un algorithme qui calcule la pertinence d'un document par rapport Ã  une requÃªte, basÃ© sur la **frÃ©quence des mots-clÃ©s**.

**CritÃ¨res considÃ©rÃ©s** :
1. **FrÃ©quence du terme** : Combien de fois le mot apparaÃ®t dans le document
2. **Longueur du document** : PÃ©nalise les documents trÃ¨s longs
3. **RaretÃ© du terme** : Les mots rares valent plus (IDF = Inverse Document Frequency)

**Exemple** :

```
Question : "procÃ©dure RTT"

Document A (1000 mots) :
â€¢ Contient "RTT" 5 fois
â€¢ Contient "procÃ©dure" 3 fois
â†’ Score BM25 Ã©levÃ© (beaucoup d'occurrences)

Document B (5000 mots) :
â€¢ Contient "RTT" 5 fois
â€¢ Contient "procÃ©dure" 3 fois
â†’ Score BM25 moyen (pÃ©nalitÃ© longueur)

Document C (500 mots) :
â€¢ Contient "RTT" 1 fois
â€¢ Ne contient pas "procÃ©dure"
â†’ Score BM25 faible
```

**PostgreSQL Full-Text Search** :

RAGFab utilise le systÃ¨me de recherche full-text natif de PostgreSQL avec **configuration franÃ§aise** :

```sql
-- Colonne prÃ©calculÃ©e avec stemming franÃ§ais
ALTER TABLE chunks ADD COLUMN content_tsv tsvector;

-- Index GIN pour recherche rapide
CREATE INDEX idx_chunks_content_tsv ON chunks USING GIN(content_tsv);

-- Trigger de mise Ã  jour automatique
CREATE TRIGGER tsvector_update
    BEFORE INSERT OR UPDATE ON chunks
    FOR EACH ROW
    EXECUTE FUNCTION chunks_tsvector_update();

-- Fonction de mise Ã  jour
CREATE FUNCTION chunks_tsvector_update() RETURNS trigger AS $
BEGIN
    NEW.content_tsv := to_tsvector('french', NEW.content);
    RETURN NEW;
END;
$ LANGUAGE plpgsql;
```

**Stemming franÃ§ais** :
```
"tÃ©lÃ©travaillent" â†’ "teletravail" (racine)
"procÃ©dures" â†’ "procedur" (racine)
"demander" â†’ "demand" (racine)
```

### 7.6 Activation et configuration

**Variables d'environnement** :

```bash
# Activer la recherche hybride
HYBRID_SEARCH_ENABLED=true

# (Optionnel) Forcer un alpha par dÃ©faut (sinon adaptatif)
# HYBRID_SEARCH_DEFAULT_ALPHA=0.5
```

**Migration requise** :

```bash
# Appliquer la migration qui crÃ©e content_tsv + index
docker-compose exec postgres psql -U raguser -d ragdb \
  -f /docker-entrypoint-initdb.d/10_hybrid_search.sql

# VÃ©rifier que la colonne est peuplÃ©e
docker-compose exec postgres psql -U raguser -d ragdb \
  -c "SELECT COUNT(*) FROM chunks WHERE content_tsv IS NOT NULL;"
```

**Logs de dÃ©bogage** :

Avec `HYBRID_SEARCH_ENABLED=true`, les logs affichent :

```
ğŸ”€ Hybrid search: query='procÃ©dure RTT' â†’ tsquery='procÃ©dure & RTT', alpha=0.30, k=5
INFO - Acronyme dÃ©tectÃ©, alpha=0.3 (keyword bias)
âœ… Hybrid search: 5 rÃ©sultats | Scores moyens - Vector: 0.765, BM25: 0.543, Combined: 0.0158
```

### 7.7 Performance et impact

**Latence supplÃ©mentaire** :
- Recherche vectorielle seule : ~30-50ms
- Recherche hybride : ~80-120ms (+50-100ms)
  - Vectorielle : ~30ms
  - BM25 : ~10-20ms (grÃ¢ce Ã  l'index GIN)
  - Fusion RRF : ~5-10ms

**Stockage supplÃ©mentaire** :
- Colonne `content_tsv` : ~15-25% de la taille du contenu original
- Index GIN : ~20-30% de la taille du contenu
- Total : ~35-55% de surcharge par chunk

**AmÃ©lioration qualitÃ©** :
- Acronymes : **+25-35% de Recall@5**
- Noms propres : **+20-30%**
- Expressions exactes : **+30-40%**
- Moyenne gÃ©nÃ©rale : **+15-25%**

---

## 8. Reranking (reclassement)

### 8.1 Qu'est-ce que le reranking ?

**Analogie** : Imaginez que vous demandez Ã  20 Ã©tudiants de rÃ©diger un rÃ©sumÃ©. Vous en sÃ©lectionnez 5 rapidement (recherche vectorielle), puis un expert les relit attentivement et les reclasse par qualitÃ© (reranking).

**Principe** :
1. **PremiÃ¨re passe** : Recherche vectorielle/hybride rapide â†’ Top-20 candidats
2. **DeuxiÃ¨me passe** : ModÃ¨le CrossEncoder analyse finement chaque paire (question, document)
3. **RÃ©sultat** : Top-5 vraiment pertinents envoyÃ©s au LLM

**Pourquoi Ã§a marche mieux ?**

La recherche vectorielle est **rapide** mais **approximative** :
- Elle compare des embeddings (vecteurs fixes)
- Ne considÃ¨re pas l'interaction question-document

Le reranker est **lent** mais **prÃ©cis** :
- Il analyse la paire complÃ¨te (question + document) ensemble
- DÃ©tecte les nuances, synonymes, contexte

### 8.2 SchÃ©ma du pipeline avec reranking

```mermaid
graph TB
    Q[â“ Question utilisateur] --> A[ğŸ” Recherche vectorielle/hybride]

    A --> B[Top-20 candidats<br/>~50ms]

    B --> C{Reranking activÃ© ?}

    C -->|Non| D[Top-5 envoyÃ©s au LLM]

    C -->|Oui| E[ğŸ§  Service Reranker<br/>BGE-reranker-v2-m3]

    E --> F[CrossEncoder analyse<br/>20 paires question-document]

    F --> G[Scores de pertinence<br/>fine-grained]

    G --> H[Tri par score<br/>+ seuil minimum]

    H --> I[Top-5 affinÃ©s<br/>~150ms supplÃ©mentaires]

    I --> J[ğŸ¤– LLM gÃ©nÃ¨re rÃ©ponse]
    D --> J

    style A fill:#e3f2fd
    style E fill:#f3e5f5
    style F fill:#ffebee
    style I fill:#e8f5e9
    style J fill:#c8e6c9
```

### 8.3 ModÃ¨le utilisÃ© : BGE-reranker-v2-m3

**SpÃ©cifications** :

| CaractÃ©ristique | DÃ©tail |
|-----------------|--------|
| **Nom complet** | BAAI/bge-reranker-v2-m3 |
| **Type** | CrossEncoder (BERT-based) |
| **Langues** | Multilingue (100+ langues) |
| **Taille** | ~560M paramÃ¨tres |
| **Performance** | Ã‰tat de l'art pour le franÃ§ais |
| **Latence** | ~7-10ms par paire |

**Pourquoi ce modÃ¨le ?**
- âœ… Excellent pour le franÃ§ais (entraÃ®nÃ© sur corpus multilingue)
- âœ… Comprend les nuances sÃ©mantiques fines
- âœ… GÃ¨re bien les termes techniques et mÃ©dicaux
- âœ… Ã‰quilibre performance/qualitÃ© optimal

### 8.4 Comment fonctionne un CrossEncoder ?

**DiffÃ©rence avec BiEncoder (vectoriel)** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ BiEncoder (Recherche vectorielle)                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Question â†’ Embedding [0.23, -0.45, ...]               â”‚
â”‚  Document â†’ Embedding [0.21, -0.43, ...]               â”‚
â”‚                                                         â”‚
â”‚  SimilaritÃ© = Cosine distance entre vecteurs           â”‚
â”‚               (calcul rapide mais approximatif)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CrossEncoder (Reranking)                                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                         â”‚
â”‚  Input : [CLS] Question [SEP] Document [SEP]           â”‚
â”‚           â†“                                             â”‚
â”‚  BERT analyze l'interaction complÃ¨te                    â”‚
â”‚           â†“                                             â”‚
â”‚  Output : Score de pertinence (0.0 Ã  1.0)              â”‚
â”‚           (analyse profonde mais lente)                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Exemple concret** :

```
Question : "Quelle est la procÃ©dure de tÃ©lÃ©travail ?"

Document A : "Le tÃ©lÃ©travail est encadrÃ© par l'accord..."
â†’ BiEncoder : score = 0.82 (vecteurs proches)
â†’ CrossEncoder : score = 0.94 (vraiment pertinent !)

Document B : "Le travail Ã  distance nÃ©cessite une demande..."
â†’ BiEncoder : score = 0.78 (vecteurs moins proches)
â†’ CrossEncoder : score = 0.91 (aussi pertinent, synonyme)

Document C : "Les horaires de travail sont de 9h Ã  17h..."
â†’ BiEncoder : score = 0.75 (contient "travail")
â†’ CrossEncoder : score = 0.23 (pas pertinent pour tÃ©lÃ©travail)
```

**RÃ©sultat** : Le CrossEncoder dÃ©tecte que Document B est trÃ¨s pertinent malgrÃ© un score vectoriel moyen (il comprend que "travail Ã  distance" = "tÃ©lÃ©travail").

### 8.5 Configuration et activation

**Variables d'environnement** :

```bash
# Activer le reranking
RERANKER_ENABLED=true

# URL du service reranker
RERANKER_API_URL=http://reranker:8002

# ModÃ¨le utilisÃ© (informatif, configurÃ© cÃ´tÃ© service)
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# Nombre de candidats avant reranking
RERANKER_TOP_K=20

# Nombre de rÃ©sultats finaux aprÃ¨s reranking
RERANKER_RETURN_K=5
```

**DÃ©ploiement du service** :

Le service reranker tourne dans un conteneur Docker sÃ©parÃ© :

```yaml
reranker:
  image: your-registry/reranker:latest
  ports:
    - "8002:8002"
  environment:
    - MODEL_NAME=BAAI/bge-reranker-v2-m3
    - DEVICE=cpu  # ou 'cuda' si GPU disponible
  deploy:
    resources:
      limits:
        memory: 4G  # ModÃ¨le nÃ©cessite ~3-4GB RAM
```

### 8.6 Quand activer le reranking ?

**Activez le reranking si** :

âœ… **Documentation technique dense** :
- Termes similaires avec significations diffÃ©rentes (ex: mÃ©dical, juridique)
- Beaucoup de concepts qui se chevauchent sÃ©mantiquement

âœ… **Base documentaire large** :
- Plus de 1000 documents
- Beaucoup de redondances entre documents

âœ… **Exigence de prÃ©cision maximale** :
- CoÃ»t d'une mauvaise rÃ©ponse Ã©levÃ© (mÃ©dical, juridique, financier)
- NÃ©cessitÃ© d'avoir les meilleurs rÃ©sultats possibles

**N'activez PAS le reranking si** :

âŒ **Latence critique** :
- Application temps rÃ©el oÃ¹ 150ms supplÃ©mentaires sont inacceptables
- Chat interactif oÃ¹ la rapiditÃ© prime

âŒ **Ressources limitÃ©es** :
- Serveur avec < 4GB RAM disponibles
- Pas de GPU et CPU limitÃ©

âŒ **Base documentaire petite** :
- Moins de 100 documents
- Documents bien structurÃ©s et distincts

### 8.7 Impact sur la performance

**Latence** :

| Ã‰tape | Sans reranking | Avec reranking |
|-------|----------------|----------------|
| Recherche vectorielle/hybride | ~80ms | ~80ms |
| Reranking (20 paires) | - | ~150ms |
| **Total** | **~80ms** | **~230ms** |

**Ressources** :

| Ressource | Avec reranking |
|-----------|----------------|
| **RAM** | +3-4GB (service reranker) |
| **CPU** | +20-30% pendant reranking |
| **GPU** | Optionnel (2-3x plus rapide) |

**QualitÃ©** :

| MÃ©trique | Sans reranking | Avec reranking | AmÃ©lioration |
|----------|----------------|----------------|--------------|
| **Precision@5** | 72% | 88% | **+16%** |
| **Recall@5** | 65% | 81% | **+16%** |
| **NDCG@5** | 0.68 | 0.84 | **+24%** |

### 8.8 Fallback en cas d'erreur

Le systÃ¨me est **robuste** : si le service reranker Ã©choue, la recherche continue sans reranking.

**ScÃ©nario** :
1. Recherche vectorielle/hybride â†’ Top-20 candidats âœ…
2. Appel au service reranker â†’ **Timeout ou erreur** âŒ
3. Fallback automatique â†’ Utilise les Top-5 de la recherche initiale âœ…
4. Log d'avertissement â†’ Admin notifiÃ©

**Code de fallback** :
```python
try:
    # Tentative de reranking
    reranked_results = await reranker_service.rerank(
        query=query,
        documents=top20_candidates,
        top_k=5
    )
    return reranked_results
except Exception as e:
    logger.warning(f"âš ï¸ Reranker failed: {e}, using vector search top-5")
    return top20_candidates[:5]  # Fallback sur top-5 vectoriel
```

**Logs** :
```
âš ï¸ Reranker service timeout after 5s, falling back to vector search
INFO - Using top-5 from vector search (scores: 0.89, 0.82, 0.78, 0.71, 0.68)
```

---

## 9. SystÃ¨me de notation et amÃ©lioration

### 9.1 Comment les utilisateurs notent

AprÃ¨s chaque rÃ©ponse du systÃ¨me, l'utilisateur peut Ã©valuer :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– Assistant: "La procÃ©dure de tÃ©lÃ©travail consiste..." â”‚
â”‚                                                         â”‚
â”‚    ğŸ“„ Sources:                                          â”‚
â”‚    â€¢ Reglement_RH.pdf (page 12) - Score: 0.89         â”‚
â”‚    â€¢ Accord_teletravail.pdf (page 3) - Score: 0.82    â”‚
â”‚                                                         â”‚
â”‚    ğŸ‘ RÃ©ponse utile    ğŸ‘ RÃ©ponse incorrecte          â”‚
â”‚    â†‘ (cliquer)         â†‘ (cliquer)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 9.2 Stockage des notes en base de donnÃ©es

**Structure** :

```sql
CREATE TABLE messages (
    id UUID PRIMARY KEY,
    conversation_id UUID REFERENCES conversations(id),
    role VARCHAR(20),           -- 'user' ou 'assistant'
    content TEXT,               -- Le message complet
    sources JSONB,              -- Sources utilisÃ©es (si assistant)
    rating VARCHAR(10),         -- 'up', 'down', ou NULL
    rated_at TIMESTAMP,         -- Quand la note a Ã©tÃ© donnÃ©e
    created_at TIMESTAMP
);
```

**Exemple d'entrÃ©es** :

```sql
-- Message utilisateur
INSERT INTO messages VALUES (
    '123e4567-...',
    'conversation-uuid',
    'user',
    'Quelle est la procÃ©dure de tÃ©lÃ©travail ?',
    NULL,              -- Pas de sources pour messages utilisateur
    NULL,              -- Pas de rating
    NULL,
    NOW()
);

-- RÃ©ponse assistant
INSERT INTO messages VALUES (
    '234f5678-...',
    'conversation-uuid',
    'assistant',
    'La procÃ©dure de tÃ©lÃ©travail consiste Ã ...',
    '[{"document": "Reglement_RH.pdf", "score": 0.89}, ...]',  -- Sources
    'up',              -- â† Note donnÃ©e par l'utilisateur
    '2025-01-24 14:35:00',
    '2025-01-24 14:34:55'
);
```

### 9.3 Analyse des notes : RequÃªtes SQL utiles

#### **Taux de satisfaction global**

```sql
SELECT
    COUNT(*) FILTER (WHERE rating = 'up') AS positives,
    COUNT(*) FILTER (WHERE rating = 'down') AS negatives,
    COUNT(*) AS total_notes,
    ROUND(
        100.0 * COUNT(*) FILTER (WHERE rating = 'up') / NULLIF(COUNT(*), 0),
        1
    ) AS taux_satisfaction_pct
FROM messages
WHERE role = 'assistant' AND rating IS NOT NULL;
```

**Exemple de rÃ©sultat** :
```
positives | negatives | total_notes | taux_satisfaction_pct
----------+-----------+-------------+----------------------
   298    |    44     |     342     |        87.1
```

#### **Documents avec mauvaises notes**

Identifier les documents sources qui apparaissent souvent dans les rÃ©ponses mal notÃ©es :

```sql
SELECT
    source_doc->>'document' AS document,
    COUNT(*) AS apparitions_total,
    COUNT(*) FILTER (WHERE m.rating = 'down') AS apparitions_negatives,
    ROUND(
        100.0 * COUNT(*) FILTER (WHERE m.rating = 'down') / COUNT(*),
        1
    ) AS pct_negatif
FROM messages m
CROSS JOIN LATERAL jsonb_array_elements(m.sources) AS source_doc
WHERE m.role = 'assistant' AND m.rating IS NOT NULL
GROUP BY source_doc->>'document'
HAVING COUNT(*) FILTER (WHERE m.rating = 'down') > 0
ORDER BY pct_negatif DESC, apparitions_negatives DESC
LIMIT 10;
```

**Exemple de rÃ©sultat** :
```
document                  | apparitions_total | apparitions_negatives | pct_negatif
--------------------------+-------------------+-----------------------+------------
ancien_reglement.pdf      |         23        |          14           |    60.9
faq_obsolete.md           |         18        |           9           |    50.0
guide_2019.pdf            |         42        |          12           |    28.6
```

**InterprÃ©tation** :
- `ancien_reglement.pdf` : 60.9% de notes nÃ©gatives â†’ **Document obsolÃ¨te ou incorrect, Ã  rÃ©ingÃ©rer ou supprimer**
- `faq_obsolete.md` : 50% de notes nÃ©gatives â†’ **Informations pÃ©rimÃ©es**
- `guide_2019.pdf` : 28.6% de notes nÃ©gatives â†’ **Peut nÃ©cessiter une mise Ã  jour**

#### **Questions frÃ©quentes avec mauvaises rÃ©ponses**

```sql
SELECT
    LEFT(m_user.content, 100) AS question_preview,
    COUNT(*) AS fois_posee,
    COUNT(*) FILTER (WHERE m_asst.rating = 'down') AS fois_mal_repondue,
    ROUND(
        100.0 * COUNT(*) FILTER (WHERE m_asst.rating = 'down') / COUNT(*),
        1
    ) AS pct_echec
FROM messages m_user
JOIN messages m_asst ON
    m_asst.conversation_id = m_user.conversation_id
    AND m_asst.created_at > m_user.created_at
    AND m_asst.role = 'assistant'
WHERE m_user.role = 'user'
  AND m_asst.rating = 'down'
GROUP BY m_user.content
HAVING COUNT(*) >= 3  -- Au moins 3 occurrences
ORDER BY fois_mal_repondue DESC
LIMIT 10;
```

**Exemple de rÃ©sultat** :
```
question_preview                                      | fois_posee | fois_mal_repondue | pct_echec
------------------------------------------------------+------------+-------------------+----------
"Quelle est la procÃ©dure pour les congÃ©s RTT ?"      |     12     |         8         |   66.7
"Comment activer mon compte PeopleDoc ?"             |      9     |         6         |   66.7
"Puis-je cumuler tÃ©lÃ©travail et horaires flexibles?" |      7     |         5         |   71.4
```

**InterprÃ©tation** :
- Ces questions sont frÃ©quentes mais mal rÃ©pondues
- Possibles causes :
  1. Information manquante dans la base documentaire
  2. Document source incorrect ou obsolÃ¨te
  3. Question nÃ©cessitant plusieurs sources (non combinÃ©es correctement)

### 9.4 Actions correctives possibles

#### **Action 1 : Supprimer un document obsolÃ¨te**

```sql
-- Identifier le document
SELECT id FROM documents WHERE title = 'ancien_reglement.pdf';

-- Supprimer (cascade supprime aussi chunks et images)
DELETE FROM documents WHERE id = 'uuid-du-document';
```

#### **Action 2 : RÃ©ingÃ©rer un document mis Ã  jour**

1. Supprimer l'ancien document (via interface admin)
2. Uploader la nouvelle version (mÃªme nom)
3. Configurer ingestion (OCR, VLM, Chunker)
4. VÃ©rifier que les questions problÃ©matiques sont mieux rÃ©pondues

#### **Action 3 : Ajouter un document manquant**

Si les notes montrent qu'une question revient souvent sans bonne rÃ©ponse :

1. Identifier le sujet (ex: "Activation PeopleDoc")
2. CrÃ©er ou trouver un document couvrant ce sujet
3. Uploader via interface admin
4. Tester la question Ã  nouveau

#### **Action 4 : Ajuster les paramÃ¨tres de recherche**

Si les notes montrent des problÃ¨mes gÃ©nÃ©raux :

- **Trop de notes nÃ©gatives sur acronymes** â†’ Activer recherche hybride, alpha=0.3
- **RÃ©ponses hors contexte** â†’ Activer reranking
- **RÃ©ponses manquant de dÃ©tails** â†’ Passer en Parent-Child chunker (contexte plus riche)

### 9.5 Monitoring continu

**Dashboard recommandÃ©** :

CrÃ©er une vue SQL pour monitoring temps rÃ©el :

```sql
CREATE OR REPLACE VIEW ratings_dashboard AS
SELECT
    DATE(m.created_at) AS date,
    COUNT(*) FILTER (WHERE m.rating = 'up') AS thumbs_up,
    COUNT(*) FILTER (WHERE m.rating = 'down') AS thumbs_down,
    COUNT(*) AS total_rated,
    ROUND(
        100.0 * COUNT(*) FILTER (WHERE m.rating = 'up') / NULLIF(COUNT(*), 0),
        1
    ) AS satisfaction_pct
FROM messages m
WHERE m.role = 'assistant' AND m.rating IS NOT NULL
GROUP BY DATE(m.created_at)
ORDER BY date DESC;
```

**Utilisation** :
```sql
-- Afficher les 7 derniers jours
SELECT * FROM ratings_dashboard LIMIT 7;
```

**RÃ©sultat attendu** :
```
date       | thumbs_up | thumbs_down | total_rated | satisfaction_pct
-----------+-----------+-------------+-------------+-----------------
2025-01-24 |    42     |      6      |     48      |      87.5
2025-01-23 |    38     |      7      |     45      |      84.4
2025-01-22 |    51     |      4      |     55      |      92.7
```

**Alertes Ã  crÃ©er** :
- âš ï¸ Si `satisfaction_pct < 70%` pendant 3 jours consÃ©cutifs â†’ EnquÃªte nÃ©cessaire
- âš ï¸ Si un document a >50% de notes nÃ©gatives â†’ RÃ©ingestion ou suppression
- âš ï¸ Si une question a >5 notes nÃ©gatives â†’ Manque de documentation

---

## 10. RÃ©ingestion des documents

### 10.1 Pourquoi rÃ©ingÃ©rer un document ?

**Situations nÃ©cessitant une rÃ©ingestion** :

1. **Document mis Ã  jour** :
   - Nouvelle version du rÃ¨glement intÃ©rieur
   - ProcÃ©dure modifiÃ©e
   - Correction d'erreurs dans le document source

2. **Mauvaises notes rÃ©currentes** :
   - Le document source gÃ©nÃ¨re beaucoup de ğŸ‘
   - Les utilisateurs signalent des informations incorrectes

3. **Changement de stratÃ©gie d'ingestion** :
   - Passage de Hybrid Ã  Parent-Child (ou inverse)
   - Changement de moteur OCR (meilleure qualitÃ© souhaitÃ©e)
   - Activation/dÃ©sactivation du VLM pour images

4. **AmÃ©lioration technique** :
   - Nouveau modÃ¨le d'embeddings dÃ©ployÃ©
   - Nouveau chunker disponible
   - Optimisations du pipeline

5. **ProblÃ¨mes dÃ©tectÃ©s** :
   - Chunks trop petits/grands
   - Embeddings de mauvaise qualitÃ© (corruption)
   - MÃ©tadonnÃ©es manquantes

### 10.2 Processus de rÃ©ingestion

#### **Ã‰tape 1 : Identifier le document problÃ©matique**

Via l'interface admin ou requÃªte SQL :

```sql
-- Documents avec plus de 50% de notes nÃ©gatives
SELECT
    d.id,
    d.title,
    d.created_at,
    COUNT(m.id) FILTER (WHERE m.rating IS NOT NULL) AS total_notes,
    COUNT(m.id) FILTER (WHERE m.rating = 'down') AS notes_negatives,
    ROUND(
        100.0 * COUNT(m.id) FILTER (WHERE m.rating = 'down')
        / NULLIF(COUNT(m.id) FILTER (WHERE m.rating IS NOT NULL), 0),
        1
    ) AS pct_negatif
FROM documents d
LEFT JOIN chunks c ON c.document_id = d.id
LEFT JOIN LATERAL (
    SELECT m.*, s->>'chunk_id' AS chunk_id_ref
    FROM messages m
    CROSS JOIN LATERAL jsonb_array_elements(m.sources) AS s
    WHERE m.role = 'assistant' AND m.rating IS NOT NULL
) m ON m.chunk_id_ref::UUID = c.id
GROUP BY d.id, d.title, d.created_at
HAVING COUNT(m.id) FILTER (WHERE m.rating = 'down') > 5
ORDER BY pct_negatif DESC;
```

#### **Ã‰tape 2 : Sauvegarder l'ancien document (optionnel)**

Avant suppression, sauvegarder l'ancien document si nÃ©cessaire :

```bash
# Copier le fichier original
cp /app/uploads/{job_id}/document.pdf /app/backups/document_old_$(date +%Y%m%d).pdf
```

Ou via SQL (export mÃ©tadonnÃ©es) :

```sql
-- Export des chunks de l'ancien document (pour comparaison)
COPY (
    SELECT c.id, c.content, c.metadata, c.chunk_index
    FROM chunks c
    WHERE c.document_id = 'uuid-du-document'
    ORDER BY c.chunk_index
) TO '/tmp/old_document_chunks.csv' CSV HEADER;
```

#### **Ã‰tape 3 : Supprimer l'ancien document**

**Via l'interface admin** :

```
1. Aller dans l'onglet "Documents"
2. Trouver le document (tri par notes nÃ©gatives disponible)
3. Cliquer sur "Supprimer" (icÃ´ne poubelle)
4. Confirmer la suppression
```

**Ou via SQL** :

```sql
-- Suppression en cascade (chunks, embeddings, images)
DELETE FROM documents WHERE id = 'uuid-du-document';

-- VÃ©rification
SELECT COUNT(*) FROM chunks WHERE document_id = 'uuid-du-document';
-- Doit retourner 0
```

**Ce qui est supprimÃ©** :
- âœ… Document lui-mÃªme (table `documents`)
- âœ… Tous les chunks (table `chunks`)
- âœ… Tous les embeddings (colonne `embedding` dans `chunks`)
- âœ… Toutes les images (table `document_images` + fichiers `/app/uploads/images`)
- âš ï¸ **CONSERVÃ‰** : Historique des conversations et notes (pour analyse)

#### **Ã‰tape 4 : RÃ©ingÃ©rer la nouvelle version**

1. **PrÃ©parer le nouveau document** :
   - TÃ©lÃ©charger la nouvelle version du PDF
   - VÃ©rifier qu'il est correct (pas de pages manquantes, texte lisible)

2. **Uploader via l'interface admin** :
   ```
   Interface Admin > Upload de documents

   ğŸ“„ SÃ©lectionner : nouveau_reglement_2025.pdf

   âš™ï¸ Configuration :
   â€¢ Moteur OCR : [RapidOCR] (si document numÃ©rique de qualitÃ©)
              OU [Tesseract] (si scan ancien)

   â€¢ Moteur VLM : [InternVL] (si contient diagrammes/tableaux)
              OU [None] (si texte pur)

   â€¢ DÃ©coupage : [Hybrid] (si document structurÃ© en sections)
              OU [Parent-Child] (si long texte continu)

   ğŸš€ Cliquer "Uploader"
   ```

3. **Suivre la progression** :
   - Barre de progression temps rÃ©el (0-100%)
   - Logs dans l'interface (Ã©tapes franchies)
   - Notification Ã  100% : "Document ingÃ©rÃ© avec succÃ¨s"

4. **VÃ©rifier l'ingestion** :
   ```sql
   -- VÃ©rifier que les chunks sont crÃ©Ã©s
   SELECT
       d.title,
       COUNT(c.id) AS chunks_count,
       COUNT(di.id) AS images_count
   FROM documents d
   LEFT JOIN chunks c ON c.document_id = d.id
   LEFT JOIN document_images di ON di.document_id = d.id
   WHERE d.title = 'nouveau_reglement_2025.pdf'
   GROUP BY d.title;
   ```

#### **Ã‰tape 5 : Tester avec les questions problÃ©matiques**

Utiliser les questions qui gÃ©nÃ©raient des notes nÃ©gatives :

```
Interface Chat > Nouvelle conversation

â“ "Quelle est la procÃ©dure pour les congÃ©s RTT ?"
   (Question qui avait 66.7% d'Ã©chec avant)

ğŸ¤– [Attendre la rÃ©ponse]

âœ… VÃ©rifier :
   â€¢ Sources citÃ©es incluent le nouveau document
   â€¢ RÃ©ponse correspond au nouveau rÃ¨glement
   â€¢ Informations Ã  jour

ğŸ‘ Noter positivement si correct
```

RÃ©pÃ©ter pour toutes les questions problÃ©matiques identifiÃ©es.

#### **Ã‰tape 6 : Comparer avec l'ancien**

Si vous avez sauvegardÃ© l'ancien document, comparer :

**MÃ©triques Ã  vÃ©rifier** :

| MÃ©trique | Ancien document | Nouveau document | AmÃ©lioration |
|----------|-----------------|------------------|--------------|
| **Nombre de chunks** | 127 | 134 | +7 (normal) |
| **Taille moyenne chunks** | 1523 tokens | 1487 tokens | -36 (OK) |
| **Images extraites** | 0 | 12 | +12 (VLM activÃ©) |
| **Notes positives** | 8/20 (40%) | 15/18 (83%) | **+43%** ğŸ‰ |

**Analyse des chunks** :

```sql
-- Comparer le contenu d'un chunk spÃ©cifique
SELECT
    old.content AS ancien_contenu,
    new.content AS nouveau_contenu
FROM
    (SELECT content FROM old_chunks WHERE chunk_index = 5) old,
    (SELECT content FROM chunks WHERE document_id = 'new-doc-id' AND chunk_index = 5) new;
```

### 10.3 RÃ©ingestion de masse (tous les documents)

**Quand le faire ?**

- Changement majeur de modÃ¨le d'embeddings
- Migration vers nouveau chunker global
- Correction d'un bug critique dans le pipeline d'ingestion

**âš ï¸ ATTENTION** : Processus lourd, prÃ©voir plusieurs heures de traitement.

**ProcÃ©dure** :

1. **Planifier une fenÃªtre de maintenance** :
   - PrÃ©venir les utilisateurs (systÃ¨me en lecture seule pendant X heures)
   - Sauvegarder la base de donnÃ©es complÃ¨te

2. **Export des documents originaux** :
   ```bash
   # Copier tous les PDFs originaux
   mkdir /tmp/documents_backup
   cp -r /app/uploads/* /tmp/documents_backup/
   ```

3. **CrÃ©er un script de rÃ©ingestion** :

   ```python
   # reingest_all.py
   import os
   import glob
   import asyncio
   from ingestion.pipeline import IngestionPipeline

   async def reingest_all():
       pipeline = IngestionPipeline()

       pdf_files = glob.glob("/tmp/documents_backup/**/*.pdf", recursive=True)

       for i, pdf_path in enumerate(pdf_files, 1):
           print(f"[{i}/{len(pdf_files)}] Processing {pdf_path}...")

           try:
               # Delete old document
               old_doc = await get_document_by_filename(os.path.basename(pdf_path))
               if old_doc:
                   await delete_document(old_doc['id'])

               # Reingest
               await pipeline.process_document(
                   file_path=pdf_path,
                   ocr_engine="rapidocr",
                   vlm_engine="internvl",
                   chunker_type="hybrid"
               )

               print(f"âœ… {pdf_path} reingested successfully")

           except Exception as e:
               print(f"âŒ {pdf_path} failed: {e}")

           # Pause entre documents (Ã©viter surcharge)
           await asyncio.sleep(2)

   if __name__ == "__main__":
       asyncio.run(reingest_all())
   ```

4. **Lancer le script** :
   ```bash
   cd rag-app
   python reingest_all.py
   ```

5. **Monitorer la progression** :
   ```bash
   # Suivre les logs
   docker-compose logs -f ingestion-worker

   # VÃ©rifier le nombre de documents ingÃ©rÃ©s
   docker-compose exec postgres psql -U raguser -d ragdb \
     -c "SELECT COUNT(*) FROM documents;"
   ```

6. **VÃ©rifier la qualitÃ©** :
   ```sql
   -- Tous les documents ont des chunks ?
   SELECT
       d.title,
       COUNT(c.id) AS chunks_count
   FROM documents d
   LEFT JOIN chunks c ON c.document_id = d.id
   GROUP BY d.id, d.title
   HAVING COUNT(c.id) = 0;
   -- Doit retourner 0 lignes
   ```

7. **Tests de non-rÃ©gression** :
   - Utiliser un jeu de questions de rÃ©fÃ©rence
   - Comparer les rÃ©ponses avant/aprÃ¨s rÃ©ingestion
   - VÃ©rifier que les notes positives restent stables ou s'amÃ©liorent

### 10.4 Bonnes pratiques

#### **Avant chaque rÃ©ingestion**

âœ… **Checklist de prÃ©paration** :
- [ ] Sauvegarder le document original (si version papier/scan)
- [ ] VÃ©rifier que le nouveau document est complet
- [ ] Noter les questions problÃ©matiques actuelles
- [ ] Sauvegarder les notes existantes (requÃªte SQL)
- [ ] Planifier un crÃ©neau de test aprÃ¨s rÃ©ingestion

#### **Choix des paramÃ¨tres d'ingestion**

| Situation | OCR recommandÃ© | VLM recommandÃ© | Chunker recommandÃ© |
|-----------|----------------|----------------|-------------------|
| **PDF numÃ©rique moderne** | RapidOCR | None (texte pur) | Hybrid |
| **PDF avec diagrammes/tableaux** | RapidOCR | InternVL | Hybrid |
| **Scan ancien (>10 ans)** | Tesseract | InternVL (si images) | Hybrid |
| **Transcription interview** | RapidOCR | None | Parent-Child |
| **Manuel technique (screenshots)** | RapidOCR | InternVL | Hybrid |

#### **AprÃ¨s rÃ©ingestion**

âœ… **Checklist de vÃ©rification** :
- [ ] Chunks crÃ©Ã©s (nombre cohÃ©rent)
- [ ] Images extraites (si VLM activÃ©)
- [ ] Tester 3-5 questions problÃ©matiques
- [ ] Comparer les rÃ©ponses avec ancien document
- [ ] VÃ©rifier les sources citÃ©es
- [ ] Monitorer les nouvelles notes pendant 48h

#### **Gestion des versions**

Si le document est frÃ©quemment mis Ã  jour (ex: FAQ trimestrielle) :

**StratÃ©gie recommandÃ©e** :
1. Inclure la date dans le titre : `FAQ_RH_2025Q1.pdf`
2. Supprimer l'ancienne version Ã  chaque mise Ã  jour
3. Garder un historique externe (SharePoint, Git LFS, etc.)

**Avantage** : Les utilisateurs voient toujours la source avec la date, savent si c'est Ã  jour.

---

## 11. Glossaire des termes techniques

### A-C

**Acronyme** : Sigle de plusieurs lettres majuscules (ex: RTT, CDI, PeopleDoc). La recherche hybride est recommandÃ©e pour bien les matcher.

**Adjacent chunks** : Chunks prÃ©cÃ©dent et suivant un chunk trouvÃ©, rÃ©cupÃ©rÃ©s pour enrichir le contexte.

**Alpha (Î±)** : ParamÃ¨tre entre 0.0 et 1.0 qui contrÃ´le l'Ã©quilibre entre recherche vectorielle (sÃ©mantique) et recherche par mots-clÃ©s dans la recherche hybride.

**BGE-reranker-v2-m3** : ModÃ¨le CrossEncoder multilingue utilisÃ© pour le reranking. Comprend 100+ langues dont le franÃ§ais.

**BiEncoder** : Type de modÃ¨le qui encode sÃ©parÃ©ment la question et les documents en vecteurs, puis calcule leur similaritÃ©. Rapide mais approximatif. UtilisÃ© pour la recherche vectorielle.

**BM25** : Algorithme de recherche par mots-clÃ©s basÃ© sur la frÃ©quence des termes. UtilisÃ© dans la recherche hybride.

**Chunk** : Morceau de texte dÃ©coupÃ© depuis un document, de taille optimale pour la recherche (~1500 tokens). Chaque chunk a son propre embedding.

**Chunker** : Composant qui dÃ©coupe les documents en chunks. RAGFab propose Hybrid Chunker et Parent-Child Chunker.

**Cosine distance / Cosine similarity** : Mesure de similaritÃ© entre deux vecteurs (embeddings). Distance de 0.0 = parfaitement identiques, distance de 2.0 = opposÃ©s. Similarity = 1 - distance.

**CrossEncoder** : Type de modÃ¨le qui analyse simultanÃ©ment la question et le document ensemble, produisant un score de pertinence. Lent mais trÃ¨s prÃ©cis. UtilisÃ© pour le reranking.

### D-G

**Docling** : BibliothÃ¨que Python avancÃ©e pour parser les documents (PDF, DOCX, etc.). Respecte la structure (sections, tableaux, listes).

**Document** : Fichier source uploadÃ© dans RAGFab (PDF, DOCX, MD, TXT, HTML).

**E5-Large** : ModÃ¨le d'embeddings multilingue utilisÃ© par RAGFab. GÃ©nÃ¨re des vecteurs de 1024 dimensions.

**EasyOCR** : Moteur OCR (Optical Character Recognition) basÃ© sur PyTorch. Standard dans Docling, bonne qualitÃ©, vitesse moyenne.

**Embedding** : ReprÃ©sentation mathÃ©matique d'un texte sous forme de vecteur de nombres (ex: 1024 dimensions). Capture le sens sÃ©mantique du texte.

**Embedding dimension** : Nombre de composantes dans un vecteur d'embedding. RAGFab utilise 1024 (E5-Large).

**Frontend** : Interface web (React) oÃ¹ les utilisateurs interagissent avec le systÃ¨me.

**Full-Text Search** : Recherche par mots-clÃ©s dans du texte. PostgreSQL utilise `tsvector` et `tsquery` avec stemming franÃ§ais.

**GIN Index** : Type d'index PostgreSQL optimisÃ© pour la recherche full-text (utilisÃ© sur `content_tsv`).

### H-O

**HNSW** : Hierarchical Navigable Small World, algorithme d'index pour la recherche vectorielle rapide (utilisÃ© par PGVector).

**Hybrid Chunker** : StratÃ©gie de dÃ©coupage qui respecte la structure du document (sections, paragraphes, tableaux). Taille variable. RecommandÃ© par dÃ©faut.

**Hybrid Search** : Combinaison de recherche vectorielle (sÃ©mantique) et recherche par mots-clÃ©s (BM25), fusionnÃ©e avec RRF.

**Ingestion** : Processus de traitement d'un document : extraction texte (OCR) â†’ extraction images (VLM) â†’ dÃ©coupage (chunking) â†’ gÃ©nÃ©ration embeddings â†’ stockage en base.

**Ingestion Worker** : Service Docker sÃ©parÃ© qui traite les jobs d'ingestion en arriÃ¨re-plan (toutes les 3 secondes).

**InternVL** : ModÃ¨le Vision-Language distant (API) pour analyser les images. GÃ©nÃ¨re descriptions sÃ©mantiques riches. ~10-15s/image.

**Job** : TÃ¢che d'ingestion enregistrÃ©e en base (`ingestion_jobs`) avec statut (`pending`, `processing`, `completed`, `failed`).

**Metadata** : Informations supplÃ©mentaires attachÃ©es Ã  un chunk (section_hierarchy, heading_context, page_number, etc.).

**OCR (Optical Character Recognition)** : Reconnaissance optique de caractÃ¨res. Extrait le texte depuis des images ou PDFs scannÃ©s.

**Overlap** : Chevauchement entre chunks adjacents (200 tokens par dÃ©faut). Assure la continuitÃ© du contexte.

### P-R

**PaddleOCR-VL** : ModÃ¨le Vision-Language local pour analyser les images. OCR multilingue rapide (109 langues). ~1-3s/image.

**Parent-Child Chunker** : StratÃ©gie de dÃ©coupage hiÃ©rarchique. Chunks parents (2000t) pour contexte riche, chunks enfants (600t) pour prÃ©cision de recherche.

**PGVector** : Extension PostgreSQL pour stocker et rechercher des vecteurs (embeddings).

**PostgreSQL** : Base de donnÃ©es relationnelle utilisÃ©e par RAGFab. Stocke documents, chunks, embeddings, conversations.

**Precision@K** : MÃ©trique de qualitÃ© de recherche. % de rÃ©sultats pertinents dans les K premiers rÃ©sultats retournÃ©s.

**RAG (Retrieval Augmented Generation)** : Technique qui combine recherche de documents (Retrieval) et gÃ©nÃ©ration de texte par IA (Generation) pour produire des rÃ©ponses basÃ©es sur des sources.

**RapidOCR** : Moteur OCR basÃ© sur PaddlePaddle, trÃ¨s rapide (~2x plus rapide qu'EasyOCR). RecommandÃ© par dÃ©faut.

**Rating** : Note donnÃ©e par l'utilisateur aprÃ¨s chaque rÃ©ponse (`'up'` ou `'down'`). StockÃ©e dans la table `messages`.

**Recall@K** : MÃ©trique de qualitÃ© de recherche. % de documents pertinents trouvÃ©s dans les K premiers rÃ©sultats (sur le total de pertinents existants).

**Reranking** : Processus de reclassement des rÃ©sultats de recherche par un modÃ¨le CrossEncoder pour amÃ©liorer la pertinence.

**RRF (Reciprocal Rank Fusion)** : Algorithme pour combiner plusieurs listes de rÃ©sultats (vectorielle + mots-clÃ©s) en une seule liste fusionnÃ©e.

### S-Z

**Score de similaritÃ©** : Valeur entre 0.0 et 1.0 indiquant Ã  quel point un chunk est pertinent pour une question (calculÃ© par cosine similarity).

**Section hierarchy** : HiÃ©rarchie des titres/sections d'un chunk (ex: `["Chapitre 1", "1.2 Config", "1.2.1 PrÃ©requis"]`).

**Semantic search** : Recherche sÃ©mantique (par le sens), utilise les embeddings. Comprend synonymes et contexte.

**Stemming** : RÃ©duction des mots Ã  leur racine (ex: "tÃ©lÃ©travaillent" â†’ "teletravail"). UtilisÃ© dans la recherche full-text PostgreSQL.

**Stopwords** : Mots trÃ¨s frÃ©quents qui apportent peu de sens (le, la, de, du, etc.). FiltrÃ©s dans la recherche par mots-clÃ©s.

**Tesseract** : Moteur OCR open-source de haute qualitÃ©, plus lent. RecommandÃ© pour scans anciens ou documents archivÃ©s.

**Token** : UnitÃ© de texte (â‰ˆ0.75 mot en franÃ§ais). Les modÃ¨les ont des limites en tokens (ex: chunk de 1500 tokens â‰ˆ 1125 mots).

**tsquery** : Format de requÃªte PostgreSQL pour la recherche full-text (ex: `procÃ©dure & tÃ©lÃ©travail`).

**tsvector** : Format de stockage PostgreSQL pour le texte indexÃ© (avec stemming et positions des mots).

**Vector** : Liste de nombres reprÃ©sentant un embedding (ex: `[0.23, -0.45, 0.78, ..., 0.12]` pour 1024 dimensions).

**Vector search** : Recherche vectorielle, compare les embeddings par distance cosine.

**VLM (Vision Language Model)** : ModÃ¨le d'IA qui analyse des images et gÃ©nÃ¨re descriptions + OCR du texte visible.

**Web API** : Service FastAPI (Python) qui gÃ¨re toutes les requÃªtes HTTP (chat, upload, admin, etc.). Port 8000.

**Worker** : Voir "Ingestion Worker".

---

## ğŸ”— Liens utiles

- **Interface utilisateur** : http://localhost:5173
- **Interface admin** : http://localhost:5173/admin
- **Documentation technique (CLAUDE.md)** : [Lien interne au projet](../CLAUDE.md)
- **Logs API** : `docker-compose logs -f ragfab-api`
- **Logs Worker** : `docker-compose logs -f ingestion-worker`

---

## ğŸ“ Support

Pour toute question technique ou problÃ¨me :

1. Consulter les logs des services concernÃ©s
2. VÃ©rifier la section "RÃ©ingestion des documents" si problÃ¨me de qualitÃ©
3. Analyser les notes utilisateurs pour identifier les documents problÃ©matiques
4. Contacter l'Ã©quipe technique avec les logs et requÃªtes SQL pertinentes

---

**Fin du guide administrateur technique RAGFab v2.0**
