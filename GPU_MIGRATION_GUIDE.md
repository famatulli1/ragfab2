# Guide Migration Reranker CPU â†’ GPU

## ğŸ¯ Objectif

Migrer le service `reranker` d'un serveur CPU vers un serveur GPU pour amÃ©liorer drastiquement les performances.

---

## ğŸ“Š Gains Attendus

### Performance Reranking

| MÃ©trique | CPU (Actuel) | GPU (Hetzner T4) | Gain |
|----------|--------------|------------------|------|
| **Latence par requÃªte** | 200-500ms | **50-150ms** | **-60-70%** âš¡ |
| **Throughput** | 5-10 req/s | **50-100 req/s** | **+900%** |
| **Batch 20 candidats** | 200-500ms | **50-150ms** | **3-4x plus rapide** |
| **Batch 50 candidats** | 800ms-1.5s | **100-200ms** | **5-7x plus rapide** |

### Impact Utilisateur Final

| Mode | CPU | GPU | AmÃ©lioration |
|------|-----|-----|--------------|
| **Mode rapide (OFF)** | 1-2s | 1-2s | Identique |
| **Mode prÃ©cis (ON)** | 2-4s | **1.5-2.5s** | **-25-40%** |
| **Activation par dÃ©faut viable** | âŒ Non | âœ… **OUI** | QualitÃ© +20-30% sans pÃ©nalitÃ© |

---

## ğŸ’° CoÃ»t Infrastructure

### Options Serveur GPU

| Provider | GPU | Prix/mois | RAM | vCPU | Recommandation |
|----------|-----|-----------|-----|------|----------------|
| **Hetzner Cloud** | Tesla T4 | **~40â‚¬** | 32GB | 8 vCPU | â­ **MEILLEUR RAPPORT QUALITÃ‰/PRIX** |
| **OVHcloud** | V100 | ~100â‚¬ | 32GB | 8 vCPU | Performant mais cher |
| **Scaleway** | V100 | ~80â‚¬ | 64GB | 16 vCPU | Bon compromis |
| **AWS g4dn.xlarge** | T4 | ~120â‚¬ | 16GB | 4 vCPU | Cher, mais fiable |
| **Azure NC4as T4** | T4 | ~150â‚¬ | 28GB | 4 vCPU | TrÃ¨s cher |

**Recommandation** : **Hetzner Cloud avec Tesla T4** - Largement suffisant pour BGE-reranker-v2-m3, excellent rapport qualitÃ©/prix.

---

## ğŸ—ï¸ Architecture RecommandÃ©e

### Option 1 : Serveur GPU DÃ©diÃ© (RECOMMANDÃ‰)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Serveur Principal (CPU) - Coolify          â”‚
â”‚                                             â”‚
â”‚  â”œâ”€ postgres                                â”‚
â”‚  â”œâ”€ embeddings (CPU)                        â”‚
â”‚  â”œâ”€ ragfab-api                              â”‚
â”‚  â”œâ”€ frontend                                â”‚
â”‚  â””â”€ ingestion-worker                        â”‚
â”‚                                             â”‚
â”‚  RERANKER_API_URL=http://<GPU_IP>:8002     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â†“
                    â”‚ HTTP
                    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Serveur GPU (Hetzner T4)                    â”‚
â”‚                                             â”‚
â”‚  â””â”€ reranker-gpu (CUDA-accelerated)        â”‚
â”‚     - Port 8002 exposÃ©                      â”‚
â”‚     - DEVICE=cuda                           â”‚
â”‚     - ~2-3GB VRAM utilisÃ©s                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Avantages** :
- âœ… Pas de migration du serveur principal
- âœ… CoÃ»t optimisÃ© : GPU uniquement pour reranker
- âœ… Scaling indÃ©pendant (peut ajouter plusieurs GPUs)
- âœ… Rollback facile si problÃ¨me
- âœ… Pas d'impact sur les autres services

---

## ğŸ“ Ã‰tape 1 : PrÃ©parer Serveur GPU

### 1.1 Provisionner Serveur Hetzner

**Specs recommandÃ©es** :
```
Type: CCX33
GPU: 1x Tesla T4 (16GB VRAM)
CPU: 8 vCPU
RAM: 32GB
Storage: 240GB SSD
OS: Ubuntu 22.04 LTS
Prix: ~40â‚¬/mois
```

**Configuration initiale** :
```bash
# SSH sur serveur GPU
ssh root@<GPU_SERVER_IP>

# Mettre Ã  jour systÃ¨me
apt update && apt upgrade -y

# Installer NVIDIA drivers
apt install -y nvidia-driver-535 nvidia-utils-535

# VÃ©rifier GPU dÃ©tectÃ©
nvidia-smi

# Attendu : Tesla T4, CUDA Version: 12.2+
```

---

### 1.2 Installer Docker avec Support GPU

```bash
# Installer Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sh get-docker.sh

# Installer NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | \
    gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

apt update
apt install -y nvidia-container-toolkit

# Configurer Docker pour GPU
nvidia-ctk runtime configure --runtime=docker
systemctl restart docker

# Tester Docker GPU
docker run --rm --gpus all nvidia/cuda:12.1.0-runtime-ubuntu22.04 nvidia-smi

# Attendu : Affichage info GPU
```

---

## ğŸ“ Ã‰tape 2 : DÃ©ployer Reranker GPU

### 2.1 TransfÃ©rer Code Reranker

```bash
# Depuis serveur principal ou machine locale
scp -r ./reranker-server root@<GPU_SERVER_IP>:/root/

# SSH sur serveur GPU
ssh root@<GPU_SERVER_IP>
cd /root/reranker-server
```

---

### 2.2 CrÃ©er docker-compose.gpu.yml

```yaml
# /root/reranker-server/docker-compose.gpu.yml
version: '3.8'

services:
  reranker-gpu:
    build:
      context: .
      dockerfile: Dockerfile.gpu
    container_name: reranker-gpu
    environment:
      RERANKER_MODEL: BAAI/bge-reranker-v2-m3
      DEVICE: cuda  # Force GPU usage
    ports:
      - "8002:8002"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8002/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 120s
```

---

### 2.3 Modifier app.py pour Forcer GPU

```bash
# VÃ©rifier que app.py utilise bien le device
nano /root/reranker-server/app.py
```

**Ajouter dÃ©tection GPU explicite** :
```python
import torch
import logging

logger = logging.getLogger(__name__)

# Forcer GPU si disponible
if torch.cuda.is_available():
    device = "cuda"
    logger.info(f"ğŸš€ GPU dÃ©tectÃ©: {torch.cuda.get_device_name(0)}")
    logger.info(f"ğŸ’¾ VRAM disponible: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB")
else:
    device = "cpu"
    logger.warning("âš ï¸ GPU non dÃ©tectÃ©, utilisation CPU")

# Charger modÃ¨le sur GPU
model = CrossEncoder(MODEL_NAME, max_length=512, device=device)
```

---

### 2.4 Build et DÃ©marrage

```bash
# Build image GPU
docker compose -f docker-compose.gpu.yml build

# DÃ©marrer service
docker compose -f docker-compose.gpu.yml up -d

# VÃ©rifier logs
docker compose -f docker-compose.gpu.yml logs -f

# Attendu :
# ğŸš€ GPU dÃ©tectÃ©: Tesla T4
# ğŸ’¾ VRAM disponible: 15.00 GB
# âœ… Reranker service started on port 8002
```

---

### 2.5 Tester Service GPU

```bash
# Test healthcheck
curl http://localhost:8002/health

# Attendu : {"status": "healthy", "device": "cuda", "model": "BAAI/bge-reranker-v2-m3"}

# Test reranking (depuis serveur GPU)
curl -X POST http://localhost:8002/rerank \
  -H "Content-Type: application/json" \
  -d '{
    "query": "Comment rÃ©soudre erreur fusappel 6102?",
    "documents": [
      {"content": "Erreur fusappel 6102: vÃ©rifier configuration", "metadata": {}},
      {"content": "Documentation fusappel", "metadata": {}}
    ]
  }'

# Attendu : RÃ©ponse en 50-150ms avec scores
```

---

## ğŸ“ Ã‰tape 3 : Configurer Serveur Principal

### 3.1 Modifier Variables Coolify

**Service : `ragfab-api`**

Coolify â†’ Service `ragfab-api` â†’ Environment Variables :

```bash
# Avant (CPU local)
RERANKER_API_URL=http://reranker:8002  # Service local

# AprÃ¨s (GPU distant)
RERANKER_API_URL=http://<GPU_SERVER_IP>:8002  # Serveur GPU externe

# ParamÃ¨tres optimisÃ©s pour GPU
RERANKER_ENABLED=true   # Redevient viable !
RERANKER_TOP_K=30       # Peut augmenter sans pÃ©nalitÃ©
RERANKER_RETURN_K=10    # Plus de contexte LLM
```

**Remplacer `<GPU_SERVER_IP>` par l'IP publique du serveur Hetzner.**

---

### 3.2 Firewall Serveur GPU

```bash
# SSH sur serveur GPU
ssh root@<GPU_SERVER_IP>

# Autoriser port 8002 depuis serveur principal uniquement (sÃ©curitÃ©)
ufw allow from <SERVEUR_PRINCIPAL_IP> to any port 8002

# OU ouvrir Ã  tous (moins sÃ©curisÃ© mais plus simple)
ufw allow 8002/tcp

# Activer firewall
ufw enable
```

---

### 3.3 RedÃ©marrer ragfab-api

```bash
# Via Coolify UI
Service ragfab-api â†’ Restart

# VÃ©rifier logs
docker logs -f ragfab-api | grep -i rerank

# Attendu :
# âœ… Reranker service accessible at http://<GPU_IP>:8002
# ğŸ”„ Reranking activÃ© par dÃ©faut
```

---

## ğŸ§ª Tests Validation

### Test 1 : VÃ©rifier Connexion GPU

```bash
# Depuis serveur principal
curl http://<GPU_SERVER_IP>:8002/health

# Attendu : {"status": "healthy", "device": "cuda"}
```

---

### Test 2 : Mesurer Latence Reranking

**Avant (CPU)** :
```bash
time curl -X POST http://localhost:8002/rerank \
  -H "Content-Type: application/json" \
  -d @test_rerank.json

# Attendu : 200-500ms
```

**AprÃ¨s (GPU)** :
```bash
time curl -X POST http://<GPU_SERVER_IP>:8002/rerank \
  -H "Content-Type: application/json" \
  -d @test_rerank.json

# Attendu : 50-150ms âš¡ (3-4x plus rapide)
```

---

### Test 3 : Test Utilisateur Final

**Avec reranking activÃ© par dÃ©faut** :
```
1. Ouvrir nouvelle conversation (toggle "Recherche approfondie" absent ou toujours ON)
2. Poser question : "Comment rÃ©soudre l'erreur fusappel 6102 ?"
3. Mesurer temps rÃ©ponse
```

**RÃ©sultat attendu** :
- âœ… Temps rÃ©ponse : **1.5-2.5s** (au lieu de 2-4s avec CPU)
- âœ… QualitÃ© : +20-30% prÃ©cision (reranking systÃ©matique)
- âœ… Logs : `"ğŸ”„ Reranking GPU: 20 candidats â†’ 10 rÃ©sultats en 80ms"`

---

### Test 4 : Monitoring GPU

```bash
# SSH sur serveur GPU
watch -n 1 nvidia-smi

# Observer pendant requÃªtes :
# - GPU Utilization: ~30-50% par requÃªte
# - Memory Used: ~2-3GB VRAM
# - Temperature: ~50-60Â°C (normal)
```

---

## ğŸ“Š RÃ©sultats Attendus

### Performance

| MÃ©trique | CPU | GPU | Gain |
|----------|-----|-----|------|
| **Latence mode prÃ©cis** | 2-4s | **1.5-2.5s** | **-25-40%** |
| **Latence reranking seul** | 200-500ms | **50-150ms** | **-60-70%** |
| **Throughput multi-users** | 5-10 req/s | **50-100 req/s** | **+900%** |
| **Batch 50 candidats** | 800ms-1.5s | **100-200ms** | **5-7x** |

### CoÃ»t

| Ã‰lÃ©ment | CoÃ»t Mensuel |
|---------|--------------|
| **Serveur GPU Hetzner T4** | ~40â‚¬ |
| **Trafic rÃ©seau** | ~2-5â‚¬ (nÃ©gligeable) |
| **Total** | **~45â‚¬/mois** |

**ROI** : Si >10 utilisateurs actifs ou si qualitÃ© +20-30% justifie 45â‚¬/mois.

---

## ğŸ¯ Recommandation Finale

### âœ… OUI, migrer sur GPU si :

1. **Budget disponible** : 40-50â‚¬/mois acceptable
2. **Multi-utilisateurs** : >5 utilisateurs simultanÃ©s prÃ©vus
3. **QualitÃ© prioritaire** : Reranking systÃ©matique souhaitÃ© sans pÃ©nalitÃ© latence
4. **Scaling futur** : PrÃ©vision charge importante

### âŒ Non, rester sur CPU si :

1. **Budget serrÃ©** : 40â‚¬/mois non justifiable
2. **Usage limitÃ©** : <5 utilisateurs, quelques requÃªtes/jour
3. **Mode manuel acceptable** : Toggle "Recherche approfondie" suffit
4. **Prototype/MVP** : Pas encore en production

---

## ğŸš€ Alternative : Optimisations CPU Sans GPU

Si budget limitÃ©, optimisations CPU possibles :

### 1. Quantization INT8

```python
# Dans app.py
from optimum.onnxruntime import ORTModelForSequenceClassification

# Charger modÃ¨le quantizÃ© (2x plus rapide sur CPU)
model = ORTModelForSequenceClassification.from_pretrained(
    "BAAI/bge-reranker-v2-m3",
    export=True,
    provider="CPUExecutionProvider"
)
```

**Gain attendu** : -30-40% latence (300-350ms â†’ 180-210ms)

---

### 2. Batch Processing OptimisÃ©

```python
# Traiter candidats par batch de 10 au lieu de 20
# Compromis latence/qualitÃ©
RERANKER_TOP_K=10  # Au lieu de 20
RERANKER_RETURN_K=5
```

**Gain attendu** : -40-50% latence (400ms â†’ 200-240ms)

---

### 3. Caching RÃ©sultats

```python
# Cache Redis pour queries frÃ©quentes
# Ã‰vite reranking pour questions identiques
from redis import Redis

cache = Redis(host='localhost', port=6379, db=0)

def rerank_with_cache(query, docs):
    cache_key = f"rerank:{hash(query)}"
    cached = cache.get(cache_key)
    if cached:
        return json.loads(cached)

    results = rerank(query, docs)
    cache.setex(cache_key, 3600, json.dumps(results))  # TTL 1h
    return results
```

**Gain** : 0ms pour queries en cache (hit rate ~20-30% en production)

---

## ğŸ“š Fichiers CrÃ©Ã©s

1. [reranker-server/Dockerfile.gpu](reranker-server/Dockerfile.gpu) - Dockerfile CUDA
2. [GPU_MIGRATION_GUIDE.md](GPU_MIGRATION_GUIDE.md) - Ce guide (nouveau)

---

## âœ… Checklist Migration GPU

### PrÃ©paration
- [ ] Provisionner serveur GPU Hetzner (Tesla T4, ~40â‚¬/mois)
- [ ] Installer NVIDIA drivers + Docker GPU support
- [ ] Tester `nvidia-smi` et `docker run --gpus all`

### DÃ©ploiement Reranker GPU
- [ ] TransfÃ©rer code reranker sur serveur GPU
- [ ] Build image avec `Dockerfile.gpu`
- [ ] DÃ©marrer service avec `docker-compose.gpu.yml`
- [ ] VÃ©rifier logs : "GPU dÃ©tectÃ©: Tesla T4"
- [ ] Test healthcheck : `curl http://localhost:8002/health`

### Configuration Serveur Principal
- [ ] Modifier `RERANKER_API_URL` vers IP serveur GPU
- [ ] Ajuster `RERANKER_ENABLED=true` (activation par dÃ©faut)
- [ ] Augmenter `RERANKER_TOP_K=30`, `RERANKER_RETURN_K=10`
- [ ] Configurer firewall serveur GPU (port 8002)
- [ ] RedÃ©marrer `ragfab-api`

### Tests Validation
- [ ] Connexion rÃ©seau : `curl http://<GPU_IP>:8002/health`
- [ ] Latence reranking : 50-150ms confirmÃ©
- [ ] Test utilisateur : Temps rÃ©ponse 1.5-2.5s
- [ ] Monitoring GPU : VRAM ~2-3GB, utilisation 30-50%

### Production
- [ ] Monitoring latence : Dashboard Grafana/Prometheus
- [ ] Alertes : Service reranker down, latence >500ms
- [ ] Backup config : `docker-compose.gpu.yml` versionnÃ©
- [ ] Documentation Ã©quipe : URL reranker, procÃ©dure rollback

---

**Date crÃ©ation** : 2025-01-10
**Auteur** : Claude Code
**Version** : 1.0 - Guide Migration Reranker GPU
