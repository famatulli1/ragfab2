# Pipeline RAG de RAGFab : Guide Complet pour Non-Techniques

## ğŸ“š Qu'est-ce qu'un systÃ¨me RAG ?

**RAG** signifie "Retrieval Augmented Generation" (GÃ©nÃ©ration AugmentÃ©e par RÃ©cupÃ©ration).

Imaginez que vous avez une bibliothÃ¨que immense avec des milliers de livres. Quand quelqu'un vous pose une question, vous devez :
1. **Trouver les bons livres** qui contiennent l'information
2. **Lire les passages pertinents**
3. **Formuler une rÃ©ponse** basÃ©e sur ce que vous avez lu

C'est exactement ce que fait notre systÃ¨me RAGFab, mais avec des documents PDF et une intelligence artificielle !

---

## ğŸ”„ Vue d'ensemble de la pipeline

Notre systÃ¨me fonctionne en **deux grandes phases** :

### Phase 1 : L'Ingestion (PrÃ©paration des documents)
C'est comme organiser une bibliothÃ¨que : on range les livres, on crÃ©e un index, on prÃ©pare tout pour pouvoir retrouver l'information rapidement.

### Phase 2 : La Restitution (RÃ©pondre aux questions)
C'est comme aider un visiteur Ã  la bibliothÃ¨que : on cherche les bons documents, on lit les passages pertinents, on formule une rÃ©ponse claire.

---

## ğŸ“¥ PHASE 1 : L'INGESTION DES DOCUMENTS

### Ã‰tape 1 : La Conversion (Docling)

**Objectif** : Transformer les PDF en texte structurÃ© comprÃ©hensible par l'ordinateur.

**Module concernÃ©** : `rag-app/ingestion/converter.py`

**Ce qui se passe** :
- Nous utilisons **Docling**, un outil spÃ©cialisÃ© qui comprend la structure des documents
- Docling ne lit pas simplement le texte comme un scanner, il **comprend** :
  - Les titres et sous-titres
  - Les paragraphes
  - Les tableaux
  - Les listes
  - La mise en page

**Exemple concret** :
```
Document PDF original :
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ TITRE : Les Ã‰nergies â”‚
â”‚                     â”‚
â”‚ Introduction        â”‚
â”‚ Le solaire est...   â”‚
â”‚                     â”‚
â”‚ Types d'Ã©nergies    â”‚
â”‚ 1. Solaire          â”‚
â”‚ 2. Ã‰olienne         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

AprÃ¨s Docling :
{
  "type": "heading",
  "text": "Les Ã‰nergies",
  "level": 1
}
{
  "type": "heading",
  "text": "Introduction",
  "level": 2
}
{
  "type": "paragraph",
  "text": "Le solaire est..."
}
...
```

**Pourquoi c'est important ?**
- Un PDF peut contenir du texte en colonnes, des images, des tableaux complexes
- Docling comprend tout Ã§a et l'organise intelligemment
- Nous obtenons un document structurÃ©, pas juste un bloc de texte

---

### Ã‰tape 2 : Le DÃ©coupage (Chunking)

**Objectif** : DÃ©couper le long document en petits morceaux digestes.

**Module concernÃ©** : `rag-app/ingestion/chunker.py`

**Pourquoi dÃ©couper ?**

Imaginez que quelqu'un vous demande "Quelle est la capitale de la France ?". Vous n'avez pas besoin de lui lire un livre entier sur la gÃ©ographie franÃ§aise, juste la phrase : "La capitale de la France est Paris."

C'est pareil pour notre IA : on dÃ©coupe les documents en **chunks** (morceaux) de taille raisonnable.

**Notre stratÃ©gie de dÃ©coupage** :

Nous utilisons **HybridChunker** de Docling qui est intelligent :

1. **Il respecte la structure du document** :
   - Il ne coupe pas un paragraphe en plein milieu
   - Il garde les titres avec leur contenu
   - Il prÃ©serve l'intÃ©gritÃ© des tableaux

2. **Configuration** :
   - Taille idÃ©ale d'un chunk : **1500 caractÃ¨res** (environ 250 mots)
   - Chevauchement entre chunks : **200 caractÃ¨res**

**Pourquoi le chevauchement ?**

Imaginez ce texte :
```
Chunk 1 : "Le solaire photovoltaÃ¯que transforme..."
Chunk 2 : "...la lumiÃ¨re en Ã©lectricitÃ©. Cette technologie..."
```

Sans chevauchement, si quelqu'un cherche "transformation de la lumiÃ¨re en Ã©lectricitÃ©", il pourrait rater l'information car elle est coupÃ©e entre deux chunks.

Avec chevauchement de 200 caractÃ¨res :
```
Chunk 1 : "Le solaire photovoltaÃ¯que transforme la lumiÃ¨re en Ã©lectricitÃ©. Cette..."
Chunk 2 : "...la lumiÃ¨re en Ã©lectricitÃ©. Cette technologie utilise..."
```

Maintenant, les deux chunks contiennent la phrase complÃ¨te !

**Fallback (plan B)** :

Si HybridChunker Ã©choue (document trop complexe), on utilise **SimpleChunker** :
- DÃ©coupe le texte aux doubles sauts de ligne (`\n\n`)
- Respecte les paragraphes naturels
- Moins intelligent mais trÃ¨s fiable

---

### Ã‰tape 3 : La Transformation en Nombres (Embeddings)

**Objectif** : Convertir le texte en "empreinte numÃ©rique" pour permettre la recherche.

**Module concernÃ©** : `rag-app/ingestion/embedder.py`

**Le concept d'embedding expliquÃ© simplement** :

Imaginez que vous voulez organiser des livres dans une bibliothÃ¨que. Vous pourriez :
- Les classer par ordre alphabÃ©tique (pas trÃ¨s utile pour chercher par thÃ¨me)
- Les classer par sujet (mieux !)
- Les placer sur une carte gÃ©ographique imaginaire oÃ¹ les livres similaires sont proches

Les **embeddings**, c'est la troisiÃ¨me option ! On transforme chaque chunk de texte en **un point dans un espace Ã  1024 dimensions**.

**Comment Ã§a marche ?**

1. On envoie le texte au service d'embeddings (modÃ¨le **E5-Large multilingue**)
2. Le modÃ¨le analyse le **sens** du texte (pas juste les mots)
3. Il retourne un vecteur de **1024 nombres** (dimensions)

**Exemple simplifiÃ©** :

```
Texte : "Le solaire photovoltaÃ¯que produit de l'Ã©lectricitÃ©"

Embedding (simplifiÃ© Ã  5 dimensions pour l'exemple) :
[0.82, 0.34, 0.91, 0.12, 0.67]

Texte similaire : "Les panneaux solaires gÃ©nÃ¨rent du courant"
[0.79, 0.31, 0.88, 0.15, 0.65]

Texte diffÃ©rent : "La cuisine franÃ§aise est renommÃ©e"
[0.12, 0.87, 0.23, 0.91, 0.34]
```

Regardez : les deux premiers textes (sur le solaire) ont des nombres similaires, le troisiÃ¨me (sur la cuisine) est trÃ¨s diffÃ©rent !

**Optimisation des performances** :

- On ne traite pas les chunks un par un (trop lent !)
- On les envoie par **lots de 20 chunks** au service d'embeddings
- Timeout de 90 secondes par lot pour Ã©viter les erreurs

**Nettoyage UTF-8** :

Les PDF peuvent contenir des caractÃ¨res bizarres (symboles spÃ©ciaux, emojis mal encodÃ©s). On nettoie tout Ã§a avant de crÃ©er les embeddings :

```python
clean_content = content.encode('utf-8', errors='replace').decode('utf-8')
```

---

### Ã‰tape 4 : Le Stockage (Base de donnÃ©es PostgreSQL + PGVector)

**Objectif** : Sauvegarder tous les chunks et leurs embeddings pour pouvoir les retrouver rapidement.

**Modules concernÃ©s** : `rag-app/database/schema.sql`, `rag-app/database/db.py`

**Structure de la base de donnÃ©es** :

Nous avons **deux tables principales** :

#### Table `documents` :
C'est la fiche d'identitÃ© de chaque document PDF.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚ Titre        â”‚ Chemin        â”‚ Date â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ Ã‰nergies.pdf â”‚ /docs/ener... â”‚ 2024 â”‚
â”‚ 2  â”‚ Climat.pdf   â”‚ /docs/clim... â”‚ 2024 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Table `chunks` :
C'est chaque morceau de texte dÃ©coupÃ©, avec son embedding.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ID â”‚ Doc â”‚ Texte             â”‚ Embedding (1024 dimensions) â”‚
â”œâ”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ 1  â”‚ 1   â”‚ "Le solaire..."   â”‚ [0.82, 0.34, 0.91, ...]    â”‚
â”‚ 2  â”‚ 1   â”‚ "Les panneaux..." â”‚ [0.79, 0.31, 0.88, ...]    â”‚
â”‚ 3  â”‚ 2   â”‚ "Le climat..."    â”‚ [0.12, 0.87, 0.23, ...]    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PGVector : l'extension magique** :

PostgreSQL normalement ne peut pas chercher dans des vecteurs de nombres. Mais avec **PGVector**, on peut :
- Stocker des vecteurs de 1024 dimensions
- Chercher les vecteurs **les plus similaires** trÃ¨s rapidement
- Utiliser l'index **HNSW** (Hierarchical Navigable Small World) pour accÃ©lÃ©rer la recherche

C'est comme avoir un GPS dans notre bibliothÃ¨que de 1024 dimensions !

**Index HNSW** :

Au lieu de comparer notre question avec TOUS les chunks (lent), l'index HNSW crÃ©e une "carte routiÃ¨re" qui permet de trouver rapidement les chunks proches.

---

## ğŸ” PHASE 2 : LA RESTITUTION (RÃ©pondre aux questions)

### Ã‰tape 1 : Reformulation de la Question (Optionnel mais intelligent)

**Objectif** : Comprendre les questions qui font rÃ©fÃ©rence Ã  la conversation prÃ©cÃ©dente.

**Module concernÃ©** : `web-api/app/main.py` (fonction `reformulate_question_with_context`)

**Le problÃ¨me des rÃ©fÃ©rences contextuelles** :

Imaginez cette conversation :

```
Utilisateur : "Quelles sont les Ã©nergies renouvelables ?"
Assistant : "Les Ã©nergies renouvelables incluent le solaire, l'Ã©olien..."

Utilisateur : "Et celle qui utilise l'eau ?"
```

La question "Et celle qui utilise l'eau ?" n'a AUCUN sens sans le contexte !

**Notre solution** :

On dÃ©tecte automatiquement les rÃ©fÃ©rences :
- **Pronoms dÃ©monstratifs** : celle, celui, celles, ceux (toujours reformulÃ©s)
- **Pronoms courts** : Ã§a, cela, ce, cette, ces (si question courte < 8 mots)
- **Pronoms en dÃ©but de phrase** : il, elle, ils, elles, y, en (si premier mot)
- **Patterns spÃ©ciaux** : "et celle", "et celui", "et Ã§a"

Puis on demande Ã  l'IA Mistral de reformuler :

```
Question originale : "Et celle qui utilise l'eau ?"
Historique rÃ©cent : ["Quelles sont les Ã©nergies renouvelables ?", "Les Ã©nergies renouvelables incluent..."]

Question reformulÃ©e : "Quelle est l'Ã©nergie renouvelable qui utilise l'eau ?"
```

**Important** : On ne reformule PAS les articles gÃ©nÃ©riques ("le", "la", "les") pour Ã©viter les fausses dÃ©tections.

---

### Ã‰tape 2 : Transformation de la Question en Embedding

**Objectif** : Convertir la question en vecteur de nombres pour la comparer aux chunks.

**Module concernÃ©** : `web-api/app/tools.py` (fonction `search_knowledge_base_tool`)

On fait exactement la mÃªme chose qu'Ã  l'ingestion :

```
Question : "Comment fonctionne l'Ã©nergie solaire ?"

Embedding de la question :
[0.80, 0.32, 0.89, 0.13, 0.66, ...]  (1024 nombres)
```

---

### Ã‰tape 3 : Recherche par SimilaritÃ© (Vector Search)

**Objectif** : Trouver les chunks les plus pertinents pour rÃ©pondre Ã  la question.

**Module concernÃ©** : `web-api/app/tools.py` (fonction `search_knowledge_base_tool`)

**Comment Ã§a marche ?**

1. On a l'embedding de la question : `[0.80, 0.32, 0.89, ...]`
2. On compare avec TOUS les embeddings des chunks dans la base
3. On utilise la **distance cosinus** pour mesurer la similaritÃ©

**Distance cosinus expliquÃ©e** :

Imaginez deux flÃ¨ches dans l'espace :
- Si elles pointent dans la mÃªme direction â†’ angle petit â†’ **trÃ¨s similaires**
- Si elles pointent dans des directions opposÃ©es â†’ angle grand â†’ **trÃ¨s diffÃ©rentes**

```
Question embedding : â”€â”€â”€â”€â”€â”€â”€â”€â–º
Chunk similaire :    â”€â”€â”€â”€â”€â”€â”€â”€â–º  (angle petit = 0.95 de similaritÃ©)
Chunk diffÃ©rent :    â†‘          (angle grand = 0.32 de similaritÃ©)
```

**RequÃªte SQL magique** :

```sql
SELECT
  c.content,
  d.title,
  1 - (c.embedding <=> $1) AS similarity
FROM chunks c
JOIN documents d ON c.document_id = d.id
ORDER BY c.embedding <=> $1
LIMIT 5
```

Traduction :
- `<=>` = opÃ©rateur de distance cosinus de PGVector
- `1 - distance` = similaritÃ© (plus proche de 1 = plus similaire)
- `ORDER BY` = trier du plus similaire au moins similaire
- `LIMIT 5` = retourner les 5 meilleurs rÃ©sultats

**RÃ©sultat** :

```
Top 5 chunks pertinents :
1. "Le solaire photovoltaÃ¯que transforme..." (similaritÃ©: 0.92)
2. "Les panneaux solaires contiennent..."    (similaritÃ©: 0.89)
3. "L'Ã©nergie solaire est renouvelable..."   (similaritÃ©: 0.85)
4. "Le photovoltaÃ¯que utilise l'effet..."    (similaritÃ©: 0.83)
5. "Les cellules photovoltaÃ¯ques sont..."    (similaritÃ©: 0.81)
```

**Stockage des sources** :

On sauvegarde ces chunks dans une **variable globale** `_current_request_sources` pour les afficher plus tard Ã  l'utilisateur.

**Pourquoi une variable globale ?**

Normalement, on prÃ©fÃ©rerait utiliser un systÃ¨me plus Ã©lÃ©gant (ContextVar), mais PydanticAI (le framework qu'on utilise pour l'IA) perd le contexte entre les appels. La variable globale fonctionne car FastAPI traite les requÃªtes une par une.

---

### Ã‰tape 4 : GÃ©nÃ©ration de la RÃ©ponse (LLM)

**Objectif** : Utiliser une IA pour formuler une rÃ©ponse basÃ©e sur les chunks trouvÃ©s.

**Module concernÃ©** : `web-api/app/main.py` (fonction `execute_rag_agent`)

**Nous avons DEUX modes** :

#### Mode 1 : Mistral avec Tools (RecommandÃ©)

**Comment Ã§a marche ?**

1. On donne Ã  l'IA Mistral un **outil** (function calling) : `search_knowledge_base_tool`
2. L'IA dÃ©cide automatiquement d'utiliser l'outil pour chercher l'information
3. L'outil retourne les chunks pertinents
4. L'IA gÃ©nÃ¨re une rÃ©ponse basÃ©e sur ces chunks

**Flow dÃ©taillÃ©** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User Question                                    â”‚
â”‚    "Comment fonctionne l'Ã©nergie solaire ?"         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Reformulation (si nÃ©cessaire)                    â”‚
â”‚    Question reformulÃ©e ou originale                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Agent Mistral crÃ©Ã© AVEC l'outil                  â”‚
â”‚    tools = [search_knowledge_base_tool]             â”‚
â”‚    message_history = []  (vide pour forcer l'outil) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Mistral dÃ©cide d'appeler l'outil                 â”‚
â”‚    "Je vais chercher des infos sur le solaire"      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Outil exÃ©cutÃ© : Vector Search                    â”‚
â”‚    - Embedding de la question                       â”‚
â”‚    - Recherche des 5 chunks similaires              â”‚
â”‚    - Sauvegarde dans _current_request_sources       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Mistral reÃ§oit les chunks                        â”‚
â”‚    "Voici les informations trouvÃ©es : ..."          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 7. Mistral gÃ©nÃ¨re la rÃ©ponse finale                 â”‚
â”‚    "L'Ã©nergie solaire photovoltaÃ¯que fonctionne..." â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 8. RÃ©ponse + Sources envoyÃ©es Ã  l'utilisateur       â”‚
â”‚    - Texte de rÃ©ponse                               â”‚
â”‚    - Liste des 5 sources (titre, contenu, page)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ParticularitÃ© importante** :

On passe `message_history=[]` (historique vide) pour **forcer** Mistral Ã  appeler l'outil Ã  chaque fois. Sinon, Mistral pourrait rÃ©pondre directement depuis l'historique de conversation sans chercher dans la base !

#### Mode 2 : Chocolatine OU Mistral sans Tools

**Comment Ã§a marche ?**

1. On exÃ©cute MANUELLEMENT la recherche vector
2. On rÃ©cupÃ¨re les chunks pertinents
3. On les **injecte directement** dans le prompt systÃ¨me de l'IA
4. L'IA gÃ©nÃ¨re une rÃ©ponse basÃ©e sur ce contexte

**Flow simplifiÃ©** :

```
Question â†’ Vector Search â†’ Injection dans prompt â†’ RÃ©ponse
```

**Exemple de prompt** :

```
SYSTÃˆME: Tu es un assistant qui rÃ©pond en franÃ§ais basÃ© sur ces documents :

DOCUMENT 1:
Le solaire photovoltaÃ¯que transforme la lumiÃ¨re en Ã©lectricitÃ©...

DOCUMENT 2:
Les panneaux solaires contiennent des cellules photovoltaÃ¯ques...

UTILISATEUR: Comment fonctionne l'Ã©nergie solaire ?

ASSISTANT: [gÃ©nÃ¨re une rÃ©ponse basÃ©e sur les documents fournis]
```

**Avantage** : Plus simple, fonctionne avec n'importe quel LLM
**InconvÃ©nient** : Moins flexible, l'IA ne peut pas dÃ©cider de chercher plus d'infos

---

### Ã‰tape 5 : Affichage des Sources

**Objectif** : Montrer Ã  l'utilisateur d'oÃ¹ viennent les informations (transparence).

**Module concernÃ©** : `frontend/src/components/SourcesList.tsx`

**Ce qui est affichÃ©** :

Pour chaque source (chunk) utilisÃ©e :
- ğŸ“„ **Titre du document** (ex: "Guide_Energies_Renouvelables.pdf")
- ğŸ“ **Extrait du texte** (les 200 premiers caractÃ¨res du chunk)
- ğŸ“ **Position** dans le document (numÃ©ro du chunk)
- ğŸ”— **Lien pour voir le document complet** (si disponible)

**Exemple visuel** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Sources utilisÃ©es pour cette rÃ©ponse :           â”‚
â”‚                                                  â”‚
â”‚ [1] ğŸ“„ Guide_Energies_Renouvelables.pdf          â”‚
â”‚     "Le solaire photovoltaÃ¯que transforme la     â”‚
â”‚      lumiÃ¨re du soleil en Ã©lectricitÃ© grÃ¢ce..."  â”‚
â”‚     ğŸ“ Chunk 12 | ğŸ”— Voir le document            â”‚
â”‚                                                  â”‚
â”‚ [2] ğŸ“„ Rapport_Transition_Energetique.pdf        â”‚
â”‚     "Les panneaux solaires sont composÃ©s de..."  â”‚
â”‚     ğŸ“ Chunk 8 | ğŸ”— Voir le document             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Pourquoi c'est important ?**

- **Transparence** : L'utilisateur sait que la rÃ©ponse vient de documents rÃ©els
- **VÃ©rifiabilitÃ©** : L'utilisateur peut vÃ©rifier l'information dans le document source
- **Confiance** : L'IA ne "hallucine" pas, elle cite ses sources

---

## ğŸ”§ Technologies UtilisÃ©es (Pour les Curieux)

### Infrastructure
- **Docker** : Conteneurisation de tous les services
- **PostgreSQL** : Base de donnÃ©es principale
- **PGVector** : Extension pour stocker et chercher dans les vecteurs

### Backend
- **FastAPI** : Framework web Python pour l'API
- **PydanticAI** : Framework pour orchestrer les agents IA
- **Docling** : Conversion et chunking intelligent des PDF
- **SQLAlchemy** : ORM pour interagir avec la base de donnÃ©es

### IA et Embeddings
- **Mistral AI** : LLM pour gÃ©nÃ©rer les rÃ©ponses
- **E5-Large Multilingue** : ModÃ¨le d'embeddings (1024 dimensions)
- **sentence-transformers** : BibliothÃ¨que pour gÃ©nÃ©rer les embeddings

### Frontend
- **React** : Framework JavaScript pour l'interface utilisateur
- **TypeScript** : JavaScript avec typage pour Ã©viter les erreurs
- **TailwindCSS** : Framework CSS pour le design
- **Vite** : Build tool moderne et rapide

---

## ğŸ“Š SchÃ©ma Complet de la Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PHASE 1 : INGESTION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Documents PDF
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. CONVERSION   â”‚  Docling lit et structure le PDF
â”‚    (Docling)    â”‚  â†’ Titres, paragraphes, tableaux
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. CHUNKING     â”‚  DÃ©coupe en morceaux de 1500 caractÃ¨res
â”‚  (HybridChunker)â”‚  â†’ Chunks avec chevauchement de 200
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. EMBEDDINGS   â”‚  Transforme en vecteurs de 1024 nombres
â”‚   (E5-Large)    â”‚  â†’ [0.82, 0.34, 0.91, ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. STOCKAGE     â”‚  Sauvegarde dans PostgreSQL + PGVector
â”‚   (PostgreSQL)  â”‚  â†’ Table chunks avec index HNSW
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  PHASE 2 : RESTITUTION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Question utilisateur
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. REFORMULATION â”‚  DÃ©tecte les rÃ©fÃ©rences contextuelles
â”‚    (Optionnel)   â”‚  â†’ "Et celle-ci ?" â†’ "Quelle est cette Ã©nergie ?"
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. EMBEDDING     â”‚  Question â†’ vecteur de 1024 nombres
â”‚   (E5-Large)     â”‚  â†’ [0.80, 0.32, 0.89, ...]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. VECTOR SEARCH â”‚  Recherche par similaritÃ© cosinus
â”‚   (PGVector)     â”‚  â†’ Top 5 chunks similaires
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. GÃ‰NÃ‰RATION    â”‚  LLM gÃ©nÃ¨re la rÃ©ponse avec contexte
â”‚   (Mistral)      â”‚  â†’ RÃ©ponse basÃ©e sur les chunks trouvÃ©s
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. AFFICHAGE     â”‚  RÃ©ponse + Sources affichÃ©es
â”‚   (React)        â”‚  â†’ Transparence et vÃ©rifiabilitÃ©
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ¯ Points ClÃ©s Ã  Retenir

### Pour l'Ingestion :
1. **Docling** comprend la structure des documents (pas juste du texte brut)
2. **HybridChunker** dÃ©coupe intelligemment en respectant le sens
3. **Embeddings** transforment le texte en "empreinte numÃ©rique" (1024 dimensions)
4. **PGVector** stocke et permet de chercher rapidement parmi des millions de chunks

### Pour la Restitution :
1. **Reformulation** rend les questions contextuelles autonomes
2. **Vector Search** trouve les chunks similaires par distance cosinus
3. **Mistral avec Tools** appelle automatiquement la recherche
4. **Sources affichÃ©es** pour la transparence et la vÃ©rifiabilitÃ©

### Pourquoi c'est Puissant :
- âœ… Cherche par **sens**, pas par mots-clÃ©s
- âœ… Fonctionne mÃªme si la question utilise des mots diffÃ©rents
- âœ… Rapide : index HNSW optimisÃ©
- âœ… Transparent : sources toujours affichÃ©es
- âœ… Multilingue : modÃ¨le E5-Large optimisÃ© pour le franÃ§ais

---

## ğŸš€ Exemple Complet de Bout en Bout

### Ingestion du document "Guide_Energies_Renouvelables.pdf"

**1. Conversion (Docling)** :
```
PDF â†’ Structure JSON
{
  "heading": "Les Ã‰nergies Renouvelables",
  "paragraph": "L'Ã©nergie solaire photovoltaÃ¯que transforme la lumiÃ¨re du soleil en Ã©lectricitÃ© grÃ¢ce Ã  l'effet photovoltaÃ¯que. Les panneaux solaires sont composÃ©s de cellules de silicium qui gÃ©nÃ¨rent un courant Ã©lectrique lorsqu'elles sont exposÃ©es Ã  la lumiÃ¨re..."
}
```

**2. Chunking (HybridChunker)** :
```
Chunk 12 (1342 caractÃ¨res) :
"L'Ã©nergie solaire photovoltaÃ¯que transforme la lumiÃ¨re du soleil en Ã©lectricitÃ© grÃ¢ce Ã  l'effet photovoltaÃ¯que. Les panneaux solaires sont composÃ©s de cellules de silicium qui gÃ©nÃ¨rent un courant Ã©lectrique lorsqu'elles sont exposÃ©es Ã  la lumiÃ¨re. Cette technologie permet de produire de l'Ã©lectricitÃ© de maniÃ¨re propre et renouvelable..."
```

**3. Embeddings (E5-Large)** :
```
Texte â†’ Vecteur
[0.1523, 0.8234, 0.4521, ..., 0.6789] (1024 nombres au total)
```

**4. Stockage (PostgreSQL)** :
```sql
INSERT INTO chunks (document_id, content, embedding, chunk_index)
VALUES (1, 'L'Ã©nergie solaire photovoltaÃ¯que...', '[0.1523, 0.8234, ...]', 12);
```

### RÃ©ponse Ã  la question "Comment l'Ã©nergie solaire produit de l'Ã©lectricitÃ© ?"

**1. Reformulation** :
```
Pas de rÃ©fÃ©rence contextuelle dÃ©tectÃ©e
â†’ Question conservÃ©e telle quelle
```

**2. Embedding de la question** :
```
"Comment l'Ã©nergie solaire produit de l'Ã©lectricitÃ© ?"
â†’ [0.1498, 0.8201, 0.4489, ..., 0.6823]
```

**3. Vector Search** :
```sql
SELECT content, title,
       1 - (embedding <=> '[0.1498, 0.8201, ...]') AS similarity
FROM chunks c JOIN documents d ON c.document_id = d.id
ORDER BY embedding <=> '[0.1498, 0.8201, ...]'
LIMIT 5;
```

**RÃ©sultats** :
```
1. Chunk 12 de "Guide_Energies_Renouvelables.pdf" (similaritÃ©: 0.94)
   "L'Ã©nergie solaire photovoltaÃ¯que transforme la lumiÃ¨re..."

2. Chunk 15 de "Guide_Energies_Renouvelables.pdf" (similaritÃ©: 0.89)
   "Les cellules photovoltaÃ¯ques sont fabriquÃ©es en silicium..."

3. Chunk 8 de "Rapport_Transition_Energetique.pdf" (similaritÃ©: 0.85)
   "Le photovoltaÃ¯que utilise l'effet photoÃ©lectrique dÃ©couvert..."

[... 2 autres chunks ...]
```

**4. GÃ©nÃ©ration avec Mistral** :

Mistral reÃ§oit :
- La question reformulÃ©e
- Les 5 chunks pertinents
- L'instruction de rÃ©pondre en franÃ§ais

Mistral gÃ©nÃ¨re :
```
"L'Ã©nergie solaire photovoltaÃ¯que produit de l'Ã©lectricitÃ© en transformant
la lumiÃ¨re du soleil en courant Ã©lectrique grÃ¢ce Ã  l'effet photovoltaÃ¯que.
Les panneaux solaires contiennent des cellules de silicium qui, lorsqu'elles
sont exposÃ©es Ã  la lumiÃ¨re, gÃ©nÃ¨rent un flux d'Ã©lectrons crÃ©ant ainsi un
courant Ã©lectrique. Cette technologie permet de produire de l'Ã©lectricitÃ©
de maniÃ¨re propre et renouvelable."
```

**5. Affichage** :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ¤– RÃ©ponse :                                               â”‚
â”‚                                                            â”‚
â”‚ L'Ã©nergie solaire photovoltaÃ¯que produit de l'Ã©lectricitÃ©  â”‚
â”‚ en transformant la lumiÃ¨re du soleil en courant            â”‚
â”‚ Ã©lectrique grÃ¢ce Ã  l'effet photovoltaÃ¯que...               â”‚
â”‚                                                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ ğŸ“š Sources utilisÃ©es :                                     â”‚
â”‚                                                            â”‚
â”‚ [1] ğŸ“„ Guide_Energies_Renouvelables.pdf                    â”‚
â”‚     "L'Ã©nergie solaire photovoltaÃ¯que transforme..."       â”‚
â”‚     ğŸ“ Chunk 12 | SimilaritÃ©: 94% | ğŸ”— Voir               â”‚
â”‚                                                            â”‚
â”‚ [2] ğŸ“„ Guide_Energies_Renouvelables.pdf                    â”‚
â”‚     "Les cellules photovoltaÃ¯ques sont fabriquÃ©es..."      â”‚
â”‚     ğŸ“ Chunk 15 | SimilaritÃ©: 89% | ğŸ”— Voir               â”‚
â”‚                                                            â”‚
â”‚ [3] ğŸ“„ Rapport_Transition_Energetique.pdf                  â”‚
â”‚     "Le photovoltaÃ¯que utilise l'effet photoÃ©lectrique..." â”‚
â”‚     ğŸ“ Chunk 8 | SimilaritÃ©: 85% | ğŸ”— Voir                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“ Glossaire des Termes Techniques

- **RAG** : Retrieval Augmented Generation - SystÃ¨me qui cherche des informations dans une base de documents pour amÃ©liorer les rÃ©ponses d'une IA

- **Chunk** : Morceau de texte dÃ©coupÃ© (gÃ©nÃ©ralement 1500 caractÃ¨res dans notre cas)

- **Embedding** : ReprÃ©sentation numÃ©rique d'un texte sous forme de vecteur (1024 nombres)

- **Vector Search** : Recherche qui compare des vecteurs pour trouver les plus similaires

- **Distance Cosinus** : Mesure de similaritÃ© entre deux vecteurs (0 = trÃ¨s diffÃ©rent, 1 = identique)

- **PGVector** : Extension PostgreSQL pour stocker et chercher dans des vecteurs

- **HNSW** : Index optimisÃ© pour accÃ©lÃ©rer la recherche dans les vecteurs

- **LLM** : Large Language Model - Grand modÃ¨le de langage (IA comme Mistral, GPT, etc.)

- **Function Calling / Tools** : CapacitÃ© d'une IA Ã  utiliser des outils externes (comme notre recherche vector)

- **Token** : UnitÃ© de texte pour l'IA (environ 0.75 mots en franÃ§ais)

---

## ğŸ“ Questions FrÃ©quentes

**Q : Pourquoi 1024 dimensions pour les embeddings ?**
R : C'est la taille du modÃ¨le E5-Large. Plus il y a de dimensions, plus la reprÃ©sentation est prÃ©cise, mais plus Ã§a prend de place en mÃ©moire. 1024 est un bon compromis.

**Q : Pourquoi dÃ©couper en chunks de 1500 caractÃ¨res ?**
R : C'est un Ã©quilibre entre :
- Trop petit â†’ perd le contexte
- Trop grand â†’ moins prÃ©cis pour la recherche
1500 caractÃ¨res = environ 2-3 paragraphes, c'est idÃ©al.

**Q : Que se passe-t-il si aucun chunk n'est similaire Ã  la question ?**
R : Le systÃ¨me retourne quand mÃªme les 5 "meilleurs" chunks (les moins pires). L'IA peut alors dire "Je n'ai pas trouvÃ© d'information pertinente dans les documents".

**Q : Peut-on ajouter des documents sans tout rÃ©-ingÃ©rer ?**
R : Oui ! Chaque document est ingÃ©rÃ© indÃ©pendamment. On peut ajouter de nouveaux PDFs sans toucher aux anciens.

**Q : Pourquoi Mistral et pas GPT-4 ?**
R : Mistral est excellent pour le franÃ§ais, open-source, et moins cher. On peut aussi facilement changer de modÃ¨le grÃ¢ce Ã  l'architecture modulaire.

---

**Ce document a Ã©tÃ© crÃ©Ã© pour expliquer la pipeline RAG de RAGFab de maniÃ¨re accessible Ã  un public non technique.**
