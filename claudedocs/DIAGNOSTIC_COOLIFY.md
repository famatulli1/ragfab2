# Diagnostic Recherche RAG sur Coolify

## Probl√®me identifi√©
Les chunks existent en base de donn√©es mais ne sont pas trouv√©s lors d'une recherche simple : "comment d√©sannuler un s√©jour annul√© √† tort"

## Option 1 : V√©rifier les logs de l'API en temps r√©el

### √âtape 1 : Connectez-vous √† votre serveur Coolify
```bash
ssh votre-serveur-coolify
```

### √âtape 2 : Visualisez les logs de l'API
```bash
# Remplacez <project-name> par le nom de votre projet Coolify
docker logs -f <project-name>-ragfab-api --tail 100

# Ou si le nom est diff√©rent :
docker ps | grep ragfab
# Puis utilisez le nom du container trouv√©
```

### √âtape 3 : Faites une recherche depuis l'interface
1. Ouvrez votre interface RAGFab dans le navigateur
2. Posez la question : "comment d√©sannuler un s√©jour annul√© √† tort"
3. Observez les logs en temps r√©el

**Recherchez dans les logs :**
- `üîß Query enrichie:` ‚Üí V√©rifier si la query est enrichie
- `üìö Sources r√©cup√©r√©es` ‚Üí V√©rifier combien de sources sont trouv√©es
- `search_knowledge_base_tool` ‚Üí V√©rifier si le tool est appel√©
- `Erreur` ou `ERROR` ‚Üí Identifier les erreurs

---

## Option 2 : Test via SQL directement en base

### √âtape 1 : Connectez-vous au container PostgreSQL
```bash
# Sur votre serveur Coolify
docker exec -it <project-name>-postgres psql -U raguser -d ragdb
```

### √âtape 2 : V√©rifiez l'√©tat de la base
```sql
-- Nombre de documents
SELECT COUNT(*) FROM documents;

-- Nombre de chunks
SELECT COUNT(*) FROM chunks;

-- Lister les documents
SELECT id, title, source, created_at FROM documents ORDER BY created_at DESC LIMIT 5;

-- V√©rifier la dimension des embeddings
SELECT array_length(embedding, 1) as dimension FROM chunks LIMIT 1;

-- V√©rifier l'index vectoriel
SELECT indexname FROM pg_indexes WHERE tablename = 'chunks' AND indexdef LIKE '%embedding%';
```

### √âtape 3 : Test de recherche vectorielle manuelle

**ATTENTION**: Cette √©tape n√©cessite de g√©n√©rer un embedding pour la query.

```sql
-- Pour tester avec un embedding factice (juste pour v√©rifier que la recherche fonctionne)
-- R√©cup√©rer un embedding existant pour test
SELECT embedding FROM chunks LIMIT 1;

-- Puis tester la recherche (remplacez <embedding> par un vrai vecteur)
SELECT
    c.content,
    d.title,
    (c.embedding <=> '<embedding>'::vector) as distance
FROM chunks c
JOIN documents d ON c.document_id = d.id
ORDER BY c.embedding <=> '<embedding>'::vector
LIMIT 5;
```

---

## Option 3 : Script de test Python dans le container

### √âtape 1 : Cr√©ez le script de test sur le serveur

```bash
# Sur votre serveur Coolify, cr√©ez un fichier
cat > /tmp/test_search.py << 'EOF'
import asyncio
import httpx
import os

async def test_search():
    # URL de votre API (ajustez si n√©cessaire)
    api_url = os.getenv("API_URL", "http://localhost:8000")

    # Test 1: V√©rifier l'API embeddings
    print("üîç Test 1: Service d'embeddings...")
    try:
        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(
                "http://embeddings:8001/embed",
                json={"texts": ["test"]}
            )
            print(f"‚úÖ Embeddings API OK (status: {response.status_code})")
            result = response.json()
            print(f"   Dimension: {len(result['embeddings'][0])}")
    except Exception as e:
        print(f"‚ùå Erreur embeddings: {e}")

    # Test 2: Recherche via l'API RAG
    print("\nüîç Test 2: Recherche RAG...")
    query = "comment d√©sannuler un s√©jour annul√© √† tort"

    try:
        async with httpx.AsyncClient(timeout=60.0) as client:
            # Vous devrez vous authentifier si n√©cessaire
            # headers = {"Authorization": "Bearer YOUR_TOKEN"}

            response = await client.post(
                f"{api_url}/api/conversations/test-conversation-id/messages",
                json={"content": query}
            )

            print(f"Status: {response.status_code}")
            if response.status_code == 200:
                result = response.json()
                print(f"‚úÖ R√©ponse re√ßue")
                print(f"   Nombre de sources: {len(result.get('sources', []))}")
                if result.get('sources'):
                    print("   Sources:")
                    for i, src in enumerate(result['sources'][:3], 1):
                        print(f"     {i}. {src.get('title', 'N/A')}")
            else:
                print(f"‚ùå Erreur: {response.text}")
    except Exception as e:
        print(f"‚ùå Erreur API: {e}")

asyncio.run(test_search())
EOF
```

### √âtape 2 : Ex√©cutez le script dans le container API
```bash
# Copiez le script dans le container
docker cp /tmp/test_search.py <project-name>-ragfab-api:/tmp/

# Ex√©cutez-le
docker exec -it <project-name>-ragfab-api python /tmp/test_search.py
```

---

## Option 4 : Test via curl (le plus simple)

### √âtape 1 : R√©cup√©rez un token d'authentification

```bash
# Remplacez par l'URL de votre instance Coolify
API_URL="https://votre-api.coolify.fr"

# Login pour obtenir un token
curl -X POST "$API_URL/api/auth/login" \
  -H "Content-Type: application/json" \
  -d '{"username": "admin", "password": "admin"}' \
  | jq -r '.access_token'

# Sauvegardez le token
TOKEN="<coller-le-token-ici>"
```

### √âtape 2 : Cr√©ez une conversation de test

```bash
curl -X POST "$API_URL/api/conversations" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"title": "Test recherche"}' \
  | jq

# R√©cup√©rez l'ID de la conversation
CONV_ID="<id-de-la-conversation>"
```

### √âtape 3 : Testez la recherche

```bash
curl -X POST "$API_URL/api/conversations/$CONV_ID/messages" \
  -H "Authorization: Bearer $TOKEN" \
  -H "Content-Type: application/json" \
  -d '{"content": "comment d√©sannuler un s√©jour annul√© √† tort"}' \
  | jq

# Observez la r√©ponse, particuli√®rement le champ "sources"
```

---

## Analyse des r√©sultats

### Si aucune source n'est trouv√©e

**Causes possibles :**

1. **Probl√®me d'embeddings**
   - Le service d'embeddings ne fonctionne pas
   - Les chunks n'ont pas d'embeddings g√©n√©r√©s
   - Solution : V√©rifier `docker logs <project-name>-embeddings`

2. **LLM n'appelle pas le tool**
   - `LLM_USE_TOOLS=false` dans la config
   - Le LLM ne comprend pas qu'il doit utiliser le tool
   - Solution : V√©rifier les variables d'environnement, forcer `LLM_USE_TOOLS=true`

3. **Probl√®me de similarit√© vectorielle**
   - Les embeddings des chunks ne matchent pas avec la query
   - Score de similarit√© trop faible
   - Solution : V√©rifier avec une query plus proche du contenu des chunks

### Si des sources sont trouv√©es mais ne semblent pas pertinentes

**Causes possibles :**

1. **Reranking d√©sactiv√©**
   - `RERANKER_ENABLED=false`
   - Solution : Activer le reranking pour am√©liorer la pr√©cision

2. **Enrichissement de query d√©faillant**
   - La query n'est pas enrichie avec le contexte conversationnel
   - Solution : V√©rifier les logs pour voir si `üîß Query enrichie` appara√Æt

3. **Chunks mal d√©coup√©s**
   - Les chunks sont trop grands ou trop petits
   - Solution : R√©ing√©rer les documents avec `CHUNK_SIZE` et `CHUNK_OVERLAP` ajust√©s

---

## Variables √† v√©rifier dans Coolify

Dans l'interface Coolify, v√©rifiez ces variables d'environnement :

```bash
# LLM Configuration
LLM_USE_TOOLS=true  # DOIT √™tre true pour function calling
LLM_API_URL=<url-de-votre-llm>
LLM_API_KEY=<cl√©-api>
LLM_MODEL_NAME=<nom-du-mod√®le>

# Embeddings
EMBEDDINGS_API_URL=http://ragfab-embeddings:8001  # Ou embeddings.internal
EMBEDDING_DIMENSION=1024

# Reranking (recommand√© pour am√©liorer la pr√©cision)
RERANKER_ENABLED=false  # Essayez avec true si probl√®me persiste
RERANKER_API_URL=http://ragfab-reranker:8002

# Adjacent chunks (contexte enrichi)
USE_ADJACENT_CHUNKS=true
```

---

## Solutions rapides selon le diagnostic

### Solution 1 : Forcer le tool calling
Si le LLM n'appelle pas le tool, modifiez dans Coolify :
```bash
LLM_USE_TOOLS=true
RAG_PROVIDER=mistral  # Ou autre provider supportant function calling
```

### Solution 2 : Activer le reranking
Si les r√©sultats sont de mauvaise qualit√© :
```bash
RERANKER_ENABLED=true
```

### Solution 3 : Am√©liorer le chunking
Si les chunks sont mal d√©coup√©s, r√©ing√©rez avec :
```bash
CHUNK_SIZE=1000  # R√©duire pour chunks plus petits et pr√©cis
CHUNK_OVERLAP=400  # Augmenter pour plus de contexte
```

### Solution 4 : V√©rifier le service d'embeddings
```bash
# Test direct du service
docker exec -it <project-name>-embeddings curl http://localhost:8001/health

# V√©rifier les logs
docker logs <project-name>-embeddings --tail 50
```

---

## Besoin d'aide ?

Si le probl√®me persiste apr√®s ces tests, partagez :
1. Les logs de l'API lors d'une recherche
2. Les r√©sultats des requ√™tes SQL (nombre de documents/chunks)
3. Les variables d'environnement LLM_* et EMBEDDINGS_*
4. La r√©ponse du test curl

Je pourrai alors vous aider √† identifier la cause exacte.
