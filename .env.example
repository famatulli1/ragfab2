# ============================================
# Configuration RAGFab
# ============================================

# -------------------------------------------
# PostgreSQL Database Configuration
# -------------------------------------------
POSTGRES_USER=raguser
POSTGRES_PASSWORD=changeme_secure_password
POSTGRES_DB=ragdb
POSTGRES_PORT=5432

# Database URL pour l'application
# Format: postgresql://user:password@host:port/database
# Local: postgresql://raguser:changeme_secure_password@localhost:5432/ragdb
# Docker: postgresql://raguser:changeme_secure_password@postgres:5432/ragdb
# Coolify: postgresql://raguser:changeme_secure_password@postgres.internal:5432/ragdb
DATABASE_URL=postgresql://raguser:changeme_secure_password@postgres:5432/ragdb

# -------------------------------------------
# Serveur d'Embeddings Configuration
# -------------------------------------------
# URL du serveur d'embeddings
# Local: http://localhost:8001
# Docker: http://embeddings:8001
# Coolify: http://embeddings.internal:8001 ou https://embeddings.votredomaine.fr
EMBEDDINGS_API_URL=http://embeddings:8001

# Port d'exposition du serveur d'embeddings
EMBEDDINGS_PORT=8001

# Modèle d'embeddings à utiliser
EMBEDDING_MODEL=intfloat/multilingual-e5-large

# Dimension des vecteurs d'embeddings (doit correspondre au modèle)
# multilingual-e5-large = 1024
# multilingual-e5-base = 768
EMBEDDING_DIMENSION=1024

# -------------------------------------------
# Serveur de Reranking Configuration
# -------------------------------------------
# Activer/désactiver le reranking (true/false)
# false = recherche vectorielle directe (comportement par défaut)
# true = vector search puis reranking pour affiner les résultats
# Recommandé: true pour documentation technique/médicale avec terminologie similaire
RERANKER_ENABLED=false

# URL du serveur de reranking
# Local: http://localhost:8002
# Docker: http://reranker:8002
# Coolify: http://reranker.internal:8002
RERANKER_API_URL=http://reranker:8002

# Port d'exposition du serveur de reranking
RERANKER_PORT=8002

# Modèle de reranking à utiliser
# BAAI/bge-reranker-v2-m3 = multilingue, excellent pour le français
RERANKER_MODEL=BAAI/bge-reranker-v2-m3

# Nombre de chunks à récupérer AVANT reranking (si RERANKER_ENABLED=true)
# Plus élevé = plus de candidats pour le reranking, mais plus lent
# Recommandé: 15-20 pour documentation technique
RERANKER_TOP_K=20

# Nombre de chunks à retourner APRÈS reranking (si RERANKER_ENABLED=true)
# C'est le nombre final de chunks envoyés au LLM
# Recommandé: 3-5 pour garder seulement les plus pertinents
RERANKER_RETURN_K=5

# -------------------------------------------
# Provider RAG Configuration
# -------------------------------------------
# Provider à utiliser: "chocolatine" (manuel) ou "mistral" (avec tools)
# NOTE: Cette variable est deprecated, utilisez LLM_USE_TOOLS à la place
RAG_PROVIDER=chocolatine

# -------------------------------------------
# Generic LLM Configuration (RECOMMENDED)
# -------------------------------------------
# URL de l'API LLM (compatible OpenAI format)
# Exemples:
#   - Mistral: https://api.mistral.ai
#   - Chocolatine: https://apigpt.mynumih.fr
#   - Ollama: http://localhost:11434
#   - LiteLLM: http://localhost:4000
LLM_API_URL=https://api.mistral.ai

# Clé API LLM (laissez vide si pas nécessaire)
LLM_API_KEY=your_api_key_here

# Nom du modèle LLM
# Exemples:
#   - Mistral: mistral-small-latest, mistral-large-latest
#   - Chocolatine: jpacifico/Chocolatine-2-14B-Instruct-v2.0.3
#   - Ollama: llama3, mistral, codellama
LLM_MODEL_NAME=mistral-small-latest

# Activer function calling (true/false)
# true = Le LLM utilise les tools (search_knowledge_base_tool) automatiquement
# false = Injection manuelle du contexte dans le prompt
LLM_USE_TOOLS=true

# Timeout pour les requêtes LLM (en secondes)
LLM_TIMEOUT=120.0

# -------------------------------------------
# API LLM Chocolatine Configuration (LEGACY)
# -------------------------------------------
# NOTE: Ces variables sont deprecated, utilisez LLM_* à la place
# Conservées pour rétrocompatibilité

# URL de votre API LLM Chocolatine-2-14B
CHOCOLATINE_API_URL=https://apigpt.mynumih.fr

# Clé API Chocolatine (si nécessaire)
CHOCOLATINE_API_KEY=

# Nom du modèle (le nom complet tel qu'il apparaît dans l'API)
CHOCOLATINE_MODEL_NAME=jpacifico/Chocolatine-2-14B-Instruct-v2.0.3

# -------------------------------------------
# API Mistral Configuration (LEGACY)
# -------------------------------------------
# NOTE: Ces variables sont deprecated, utilisez LLM_* à la place
# Conservées pour rétrocompatibilité

# Clé API Mistral (obtenir sur https://console.mistral.ai/api-keys)
MISTRAL_API_KEY=your_mistral_api_key_here

# URL de l'API Mistral
MISTRAL_API_URL=https://api.mistral.ai

# Nom du modèle Mistral à utiliser
# Options: open-mistral-7b, mistral-small-latest, mistral-medium-latest, mistral-large-latest
MISTRAL_MODEL_NAME=mistral-small-latest

# Timeout pour les requêtes Mistral (en secondes)
MISTRAL_TIMEOUT=120.0

# -------------------------------------------
# Ingestion Configuration
# -------------------------------------------
# Taille des chunks (en caractères)
CHUNK_SIZE=1500

# Chevauchement entre les chunks
CHUNK_OVERLAP=200

# Taille maximale d'un chunk
MAX_CHUNK_SIZE=2000

# Activer le chunking sémantique (true/false)
USE_SEMANTIC_CHUNKING=true

# -------------------------------------------
# Ingestion Worker Configuration
# -------------------------------------------
# Intervalle de polling du worker (en secondes)
WORKER_POLL_INTERVAL=3

# Timeout pour considérer un job comme bloqué (en minutes)
WORKER_TIMEOUT_MINUTES=30

# Répertoire de stockage des fichiers uploadés
UPLOAD_DIR=/app/uploads

# Taille maximale des fichiers uploadés (en MB)
MAX_UPLOAD_SIZE=100

# -------------------------------------------
# Web API & Frontend Configuration
# -------------------------------------------
# Port de l'API Backend
API_PORT=8000

# Port du Frontend
FRONTEND_PORT=3000

# URL de l'API Backend (utilisée par le frontend)
# Dev: http://localhost:8000
# Prod: https://api-rag.votredomaine.fr
VITE_API_URL=http://localhost:8000

# CORS: Origines autorisées (séparées par virgule)
# Exemple: https://rag.votredomaine.fr,https://api-rag.votredomaine.fr
# En dev, localhost est autorisé par défaut
CORS_ORIGINS=

# JWT Secret (à changer en production)
JWT_SECRET=your-secret-key-change-in-production

# Admin credentials
ADMIN_USERNAME=admin
ADMIN_PASSWORD=admin

# -------------------------------------------
# VLM (Vision Language Model) Configuration
# -------------------------------------------
# Activer/désactiver l'extraction d'images avec VLM (true/false)
# true = Analyse images dans PDFs avec VLM distant
# false = Pas d'extraction d'images
VLM_ENABLED=false

# URL de l'API VLM distante (compatible OpenAI)
# Exemples: https://your-vlm-api.com/v1, http://localhost:8003/v1
VLM_API_URL=https://your-vlm-api.com/v1

# Clé API pour le service VLM
VLM_API_KEY=

# Modèle VLM à utiliser
# Recommandé: SmolDocling-256M (rapide, ~6s/page)
# Alternatives: Qwen2.5-VL-3B, pixtral-12b, granite-vision-3.2-2b
VLM_MODEL_NAME=SmolDocling-256M

# Timeout pour les requêtes VLM (en secondes)
VLM_TIMEOUT=60.0

# Prompt pour l'analyse des images
VLM_PROMPT=Décris cette image en détail en français. Extrais tout le texte visible.

# -------------------------------------------
# Image Processing Configuration
# -------------------------------------------
# Répertoire de stockage des images extraites
# /app/uploads/images dans Docker
IMAGE_STORAGE_PATH=/app/uploads/images

# Taille maximale des images à extraire (en MB)
IMAGE_MAX_SIZE_MB=10

# Qualité de compression JPEG pour les images (1-100)
IMAGE_QUALITY=85

# Format de sortie des images (png, jpeg)
IMAGE_OUTPUT_FORMAT=png

# -------------------------------------------
# Application Configuration
# -------------------------------------------
# Niveau de log (DEBUG, INFO, WARNING, ERROR)
LOG_LEVEL=INFO

# Mode debug (true/false)
DEBUG_MODE=false

# -------------------------------------------
# Docker / Coolify Configuration
# -------------------------------------------
# Ces variables sont utilisées uniquement pour le déploiement

# Limites de ressources pour embeddings (CPU cores)
EMBEDDINGS_CPU_LIMIT=4
EMBEDDINGS_CPU_RESERVATION=2

# Limites de mémoire pour embeddings (en GB)
EMBEDDINGS_MEMORY_LIMIT=8
EMBEDDINGS_MEMORY_RESERVATION=4
