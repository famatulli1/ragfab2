# RAGFab Ingestion Worker

Service worker permanent qui traite l'ingestion de documents upload√©s via l'interface admin.

## Architecture

```
Frontend Upload ‚Üí Web API ‚Üí PostgreSQL (ingestion_jobs)
                              ‚Üì (poll every 3s)
                    Ingestion Worker
                              ‚Üì
                    Document Processing Pipeline
                              ‚Üì
                    PostgreSQL (documents + chunks)
```

## Fonctionnement

### 1. Upload (Interface Admin)

L'utilisateur uploade un document via l'interface admin :

- Fichier valid√© (type + taille < 100MB)
- Sauvegard√© dans `/app/uploads/{job_id}/filename.pdf`
- Job cr√©√© dans `ingestion_jobs` avec `status='pending'`

### 2. Worker Loop (Service Permanent)

Le worker tourne en continu et :

1. **Poll PostgreSQL** toutes les 3 secondes
2. **D√©tecte les jobs pending**
3. **Claim le job** (status ‚Üí `processing`)
4. **Traite le document** :
   - Lecture avec Docling (PDF, DOCX, etc.)
   - Chunking avec HybridChunker
   - G√©n√©ration embeddings (E5-Large)
   - Sauvegarde dans PostgreSQL
5. **Met √† jour progress** (0% ‚Üí 100%)
6. **Finalise le job** (status ‚Üí `completed` ou `failed`)

### 3. Frontend Polling

Le frontend poll l'API toutes les 2 secondes :

```typescript
GET /api/admin/documents/jobs/{job_id}
```

Affiche une progress bar en temps r√©el.

## Variables d'environnement

```bash
# Database
DATABASE_URL=postgresql://user:pass@postgres:5432/ragdb

# Embeddings
EMBEDDINGS_API_URL=http://embeddings:8001
EMBEDDING_DIMENSION=1024

# Chunking
CHUNK_SIZE=1500
CHUNK_OVERLAP=200
USE_SEMANTIC_CHUNKING=true

# Worker configuration
WORKER_POLL_INTERVAL=3          # Poll interval in seconds
WORKER_TIMEOUT_MINUTES=30       # Timeout for stuck jobs
UPLOADS_DIR=/app/uploads        # Shared volume with API
```

## Volume Partag√©

Le volume `api_uploads` est partag√© entre :

- **ragfab-api** : Upload et stockage des fichiers
- **ingestion-worker** : Lecture et traitement des fichiers

```yaml
volumes:
  api_uploads:
    driver: local
```

## Gestion des Erreurs

### Job Timeout

Si un job reste en `processing` > 30 minutes :

- Consid√©r√© comme "stuck" (worker crash probable)
- Reset automatique √† `status='pending'` au d√©marrage du worker
- Sera retrait√© automatiquement

### √âchecs de Traitement

En cas d'erreur pendant le traitement :

- `status='failed'`
- `error_message` contient le d√©tail de l'erreur
- Fichier upload√© nettoy√©
- Visible dans l'interface admin

### Retry

Actuellement, pas de retry automatique. Les jobs failed restent en base pour analyse.

**Extension future** : Ajouter un compteur de retry et r√©essayer automatiquement les jobs failed.

## Formats Support√©s

Le worker supporte tous les formats g√©r√©s par Docling :

- **Documents** : PDF, DOCX, DOC, PPTX, PPT
- **Tableurs** : XLSX, XLS
- **Web** : HTML, HTM
- **Texte** : MD, TXT

## Monitoring

### Logs Worker

```bash
docker-compose logs -f ingestion-worker
```

Messages cl√©s :

- `üöÄ Worker started (polling every 3s)`
- `üìÑ Processing job {job_id}: {filename}`
- `‚úÖ Job {job_id} completed: {chunks_created} chunks created`
- `‚ùå Job {job_id} failed: {error_message}`

### Statut Jobs

Via l'API :

```bash
# Statut d'un job
GET /api/admin/documents/jobs/{job_id}

# Liste de tous les jobs
GET /api/admin/documents/jobs?status_filter=processing

# R√©ponse
{
  "id": "uuid",
  "filename": "document.pdf",
  "status": "processing",  # pending, processing, completed, failed
  "progress": 45,          # 0-100%
  "chunks_created": 0,
  "error_message": null,
  "created_at": "2025-01-10T10:00:00Z",
  "started_at": "2025-01-10T10:00:05Z",
  "completed_at": null
}
```

## Performance

### Ressources Allou√©es

```yaml
deploy:
  resources:
    limits:
      cpus: '2'
      memory: 4G
    reservations:
      cpus: '1'
      memory: 2G
```

### Temps de Traitement Typiques

- **PDF 10 pages** : ~30-60 secondes
- **PDF 50 pages** : ~2-3 minutes
- **DOCX 100 pages** : ~3-5 minutes

Facteurs :

- Docling parsing : ~50% du temps
- Embeddings generation : ~40% du temps
- Database save : ~10% du temps

## D√©veloppement

### Test Local

```bash
# Build et d√©marrage
docker-compose up -d ingestion-worker

# Logs en temps r√©el
docker-compose logs -f ingestion-worker

# Restart apr√®s modifications
docker-compose restart ingestion-worker
```

### Debug Mode

Activer logs d√©taill√©s :

```python
# worker.py
logging.basicConfig(level=logging.DEBUG)
```

### Test d'Upload

1. Connectez-vous √† l'admin : `http://localhost:3000/admin`
2. Uploadez un document PDF
3. Surveillez les logs du worker
4. V√©rifiez la progression dans l'interface

## Extensions Futures

### 1. Server-Sent Events (SSE)

Remplacer le polling par SSE pour push temps r√©el :

```python
@router.get("/ingestion/stream")
async def ingestion_stream():
    async def event_generator():
        while True:
            # Push events to client
            yield f"data: {json.dumps(status)}\n\n"
```

### 2. Multi-Workers

Plusieurs workers en parall√®le pour haute charge :

```yaml
ingestion-worker:
  deploy:
    replicas: 3  # 3 workers simultan√©s
```

### 3. Job Priorit√©

Ajouter une colonne `priority` pour traiter les jobs urgents en premier :

```sql
ALTER TABLE ingestion_jobs ADD COLUMN priority INTEGER DEFAULT 0;
```

### 4. Upload par Batch

G√©rer plusieurs fichiers en un seul job :

```typescript
// Frontend
uploadMultiple(files: File[])
```

### 5. Notification Completion

Email ou webhook √† la fin du traitement :

```python
# worker.py
await send_notification(user_email, job_status)
```

## D√©pannage

### Worker ne d√©marre pas

```bash
# V√©rifier logs
docker-compose logs ingestion-worker

# Erreurs communes
# 1. Database connection failed ‚Üí V√©rifier DATABASE_URL
# 2. Embeddings service not ready ‚Üí Attendre embeddings healthcheck
# 3. Volume not mounted ‚Üí V√©rifier docker-compose.yml volumes
```

### Jobs restent pending

```bash
# V√©rifier que le worker tourne
docker-compose ps ingestion-worker

# V√©rifier les logs pour erreurs
docker-compose logs -f ingestion-worker

# Restart worker si n√©cessaire
docker-compose restart ingestion-worker
```

### Fichier upload√© manquant

```bash
# V√©rifier le volume
docker-compose exec ingestion-worker ls -la /app/uploads/

# V√©rifier que le fichier a bien √©t√© upload√©
docker-compose exec ragfab-api ls -la /app/uploads/{job_id}/
```

## Support

Pour tout probl√®me :

1. V√©rifiez les logs : `docker-compose logs -f ingestion-worker`
2. V√©rifiez les jobs en base : `SELECT * FROM ingestion_jobs ORDER BY created_at DESC;`
3. Consultez le fichier CLAUDE.md pour l'architecture compl√®te
